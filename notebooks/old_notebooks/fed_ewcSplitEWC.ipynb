{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfadd156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grbagwe/miniconda3/envs/fedconlearn/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, \\\n",
    "accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \\\n",
    "confusion_matrix_metrics, disk_usage_metrics\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training import Naive,EWC\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, Resize\n",
    "import wandb\n",
    "import timm\n",
    "import torch\n",
    "import avalanche\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780f7ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST,CIFAR10\n",
    "from avalanche.benchmarks.datasets.dataset_utils import default_dataset_location\n",
    "\n",
    "mnist_train = MNIST(\n",
    "            root = default_dataset_location(\"mnist\"),\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=ToTensor(),\n",
    "        )\n",
    "mnist_test = MNIST(\n",
    "            root = default_dataset_location(\"mnist\"),\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=ToTensor(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90578cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993a6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea258217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = Compose([\n",
    "    Resize(224),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    Resize(224),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "benchmark = avalanche.benchmarks.SplitCIFAR10(n_experiences=5, return_task_id=False, \n",
    "                       train_transform=train_transform,eval_transform = test_transform\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a4e7db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequence.count of <avalanche.benchmarks.scenarios.classification_scenario.ClassificationStream object at 0x7f12b56ade50>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e226f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrbagwe\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grbagwe/Projects/promptFCL/notebooks/wandb/run-20230131_164422-3uepqd8o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/grbagwe/avalanche/runs/3uepqd8o\" target=\"_blank\">fed-ewc-SplitCIFAR10</a></strong> to <a href=\"https://wandb.ai/grbagwe/avalanche\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loggers \n",
    "loggers = []\n",
    "\n",
    "# log to Tensorboard\n",
    "loggers.append(TensorboardLogger())\n",
    "\n",
    "# log to text file\n",
    "loggers.append(TextLogger(open('log.txt', 'a')))\n",
    "\n",
    "# print to stdout\n",
    "loggers.append(InteractiveLogger())\n",
    "\n",
    "# W&B logger - comment this if you don't have a W&B account\n",
    "loggers.append(WandBLogger(project_name=\"avalanche\", run_name=\"fed-ewc-SplitCIFAR10\"))\n",
    "\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    timing_metrics(epoch=True, epoch_running=True),\n",
    "    cpu_usage_metrics(experience=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    confusion_matrix_metrics(num_classes=benchmark.n_classes, save_image=True,\n",
    "                             stream=True),\n",
    "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=loggers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3bc6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.models.vit_tiny_patch16_224(pretrained=True, num_classes=benchmark.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b75a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE STRATEGY INSTANCE (EWC)\n",
    "cl_strategy = EWC(\n",
    "    model,\n",
    "    optimizer=SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "    criterion=CrossEntropyLoss(),\n",
    "    ewc_lambda=0.4,\n",
    "    train_mb_size=50, train_epochs=5,\n",
    "    eval_mb_size=50,device='cuda:1',\n",
    "    evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a284b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING LOOP\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start training on experience \", experience.current_experience)\n",
    "\n",
    "    cl_strategy.train(experience)\n",
    "    print(\"End training on experience\", experience.current_experience)\n",
    "    print(\"Computing accuracy on the test set\")\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream[:]))\n",
    "        \n",
    "        \n",
    "# for experience in benchmark.train_stream:\n",
    "#     # train returns a dictionary which contains all the metric values\n",
    "#     res = cl_strategy.train(experience)\n",
    "#     print('Training completed')\n",
    "\n",
    "#     print('Computing accuracy on the whole test set')\n",
    "    # test also returns a dictionary which contains all the metric values    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fedconlearn] *",
   "language": "python",
   "name": "conda-env-fedconlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
