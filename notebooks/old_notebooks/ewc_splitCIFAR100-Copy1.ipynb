{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34a6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grbagwe/miniconda3/envs/fedconlearn/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, \\\n",
    "accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \\\n",
    "confusion_matrix_metrics, disk_usage_metrics, bwt_metrics\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training import Naive,EWC\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop, Resize\n",
    "import numpy as np\n",
    "import random\n",
    "import wandb\n",
    "import timm\n",
    "import torch\n",
    "import avalanche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1e0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b586c65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transform = Compose([\n",
    "    Resize(224),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = Compose([\n",
    "    Resize(224),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "benchmark = avalanche.benchmarks.SplitCIFAR100(n_experiences=10, return_task_id=False, seed=seed, \n",
    "                       train_transform=train_transform,eval_transform = test_transform\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5643ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{5, 9, 23, 37, 39, 48, 58, 62, 86, 96},\n",
       " {7, 18, 19, 28, 33, 41, 67, 69, 78, 99},\n",
       " {17, 29, 36, 44, 47, 66, 74, 80, 83, 88},\n",
       " {6, 20, 21, 27, 43, 51, 81, 82, 85, 90},\n",
       " {1, 4, 14, 63, 65, 73, 84, 91, 93, 95},\n",
       " {2, 10, 12, 32, 53, 54, 59, 75, 89, 92},\n",
       " {31, 34, 35, 40, 42, 45, 55, 64, 97, 98},\n",
       " {0, 8, 24, 38, 49, 52, 68, 71, 79, 87},\n",
       " {15, 16, 22, 25, 30, 50, 56, 57, 61, 94},\n",
       " {3, 11, 13, 26, 46, 60, 70, 72, 76, 77}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.original_classes_in_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e5109e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids_from_zero_from_first_exp': False,\n",
       " 'class_ids_from_zero_in_each_exp': False,\n",
       " 'class_mapping': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99],\n",
       " 'classes_order': [39,\n",
       "  48,\n",
       "  62,\n",
       "  58,\n",
       "  37,\n",
       "  9,\n",
       "  5,\n",
       "  86,\n",
       "  96,\n",
       "  23,\n",
       "  41,\n",
       "  69,\n",
       "  18,\n",
       "  7,\n",
       "  67,\n",
       "  78,\n",
       "  99,\n",
       "  28,\n",
       "  19,\n",
       "  33,\n",
       "  17,\n",
       "  36,\n",
       "  29,\n",
       "  80,\n",
       "  88,\n",
       "  44,\n",
       "  66,\n",
       "  47,\n",
       "  83,\n",
       "  74,\n",
       "  51,\n",
       "  81,\n",
       "  90,\n",
       "  20,\n",
       "  82,\n",
       "  27,\n",
       "  85,\n",
       "  6,\n",
       "  43,\n",
       "  21,\n",
       "  95,\n",
       "  14,\n",
       "  84,\n",
       "  1,\n",
       "  73,\n",
       "  91,\n",
       "  4,\n",
       "  93,\n",
       "  63,\n",
       "  65,\n",
       "  59,\n",
       "  2,\n",
       "  92,\n",
       "  54,\n",
       "  53,\n",
       "  75,\n",
       "  12,\n",
       "  89,\n",
       "  10,\n",
       "  32,\n",
       "  31,\n",
       "  64,\n",
       "  45,\n",
       "  34,\n",
       "  35,\n",
       "  55,\n",
       "  42,\n",
       "  98,\n",
       "  40,\n",
       "  97,\n",
       "  49,\n",
       "  79,\n",
       "  68,\n",
       "  0,\n",
       "  24,\n",
       "  71,\n",
       "  52,\n",
       "  87,\n",
       "  38,\n",
       "  8,\n",
       "  30,\n",
       "  16,\n",
       "  56,\n",
       "  25,\n",
       "  57,\n",
       "  50,\n",
       "  61,\n",
       "  15,\n",
       "  22,\n",
       "  94,\n",
       "  72,\n",
       "  26,\n",
       "  13,\n",
       "  70,\n",
       "  76,\n",
       "  60,\n",
       "  77,\n",
       "  3,\n",
       "  46,\n",
       "  11],\n",
       " 'classes_order_original_ids': [39,\n",
       "  48,\n",
       "  62,\n",
       "  58,\n",
       "  37,\n",
       "  9,\n",
       "  5,\n",
       "  86,\n",
       "  96,\n",
       "  23,\n",
       "  41,\n",
       "  69,\n",
       "  18,\n",
       "  7,\n",
       "  67,\n",
       "  78,\n",
       "  99,\n",
       "  28,\n",
       "  19,\n",
       "  33,\n",
       "  17,\n",
       "  36,\n",
       "  29,\n",
       "  80,\n",
       "  88,\n",
       "  44,\n",
       "  66,\n",
       "  47,\n",
       "  83,\n",
       "  74,\n",
       "  51,\n",
       "  81,\n",
       "  90,\n",
       "  20,\n",
       "  82,\n",
       "  27,\n",
       "  85,\n",
       "  6,\n",
       "  43,\n",
       "  21,\n",
       "  95,\n",
       "  14,\n",
       "  84,\n",
       "  1,\n",
       "  73,\n",
       "  91,\n",
       "  4,\n",
       "  93,\n",
       "  63,\n",
       "  65,\n",
       "  59,\n",
       "  2,\n",
       "  92,\n",
       "  54,\n",
       "  53,\n",
       "  75,\n",
       "  12,\n",
       "  89,\n",
       "  10,\n",
       "  32,\n",
       "  31,\n",
       "  64,\n",
       "  45,\n",
       "  34,\n",
       "  35,\n",
       "  55,\n",
       "  42,\n",
       "  98,\n",
       "  40,\n",
       "  97,\n",
       "  49,\n",
       "  79,\n",
       "  68,\n",
       "  0,\n",
       "  24,\n",
       "  71,\n",
       "  52,\n",
       "  87,\n",
       "  38,\n",
       "  8,\n",
       "  30,\n",
       "  16,\n",
       "  56,\n",
       "  25,\n",
       "  57,\n",
       "  50,\n",
       "  61,\n",
       "  15,\n",
       "  22,\n",
       "  94,\n",
       "  72,\n",
       "  26,\n",
       "  13,\n",
       "  70,\n",
       "  76,\n",
       "  60,\n",
       "  77,\n",
       "  3,\n",
       "  46,\n",
       "  11],\n",
       " 'n_classes_per_exp': [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       " 'n_experiences': 10,\n",
       " 'has_task_labels': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.get_reproducibility_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028bf4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.models.vit_tiny_patch16_224(pretrained=True, num_classes=benchmark.n_classes)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38245ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (act): GELU()\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head): Linear(in_features=192, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a25b8b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrbagwe\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grbagwe/Projects/promptFCL/notebooks/wandb/run-20230201_113906-b948doyu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/grbagwe/avalanche/runs/b948doyu\" target=\"_blank\">ewc-SplitCifar100-Vit</a></strong> to <a href=\"https://wandb.ai/grbagwe/avalanche\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loggers \n",
    "loggers = []\n",
    "\n",
    "# log to Tensorboard\n",
    "loggers.append(TensorboardLogger())\n",
    "\n",
    "# log to text file\n",
    "loggers.append(TextLogger(open('log.txt', 'a')))\n",
    "\n",
    "# print to stdout\n",
    "loggers.append(InteractiveLogger())\n",
    "\n",
    "# W&B logger - comment this if you don't have a W&B account\n",
    "loggers.append(WandBLogger(project_name=\"avalanche\", run_name=\"ewc-SplitCifar100-Vit\"))\n",
    "\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "#     timing_metrics(epoch=True, epoch_running=True),\n",
    "#     cpu_usage_metrics(experience=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    bwt_metrics(experience=True, stream=True),\n",
    "    confusion_matrix_metrics(num_classes=benchmark.n_classes, save_image=True,\n",
    "                             stream=True),\n",
    "#     disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=loggers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee290fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE STRATEGY INSTANCE (EWC)\n",
    "cl_strategy = EWC(\n",
    "    model,\n",
    "    optimizer=SGD(model.parameters(), lr=0.0001),\n",
    "    criterion=CrossEntropyLoss(),\n",
    "    ewc_lambda=0.7,\n",
    "    train_mb_size=50, train_epochs=10,\n",
    "    eval_mb_size=50,device='cuda',\n",
    "    evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c52f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start training on experience  0\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:28<00:00,  3.51it/s]\n",
      "Epoch 0 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 205938.8428\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 205938.8428\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.6011\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7669\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1400\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2200\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.81it/s]\n",
      "Epoch 1 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 206113.6230\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 206113.6230\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0657\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5154\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5086\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6600\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.02it/s]\n",
      "Epoch 2 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 206266.5225\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 206266.5225\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2710\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1178\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7472\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7400\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.13it/s]\n",
      "Epoch 3 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 206436.9902\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 206436.9902\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8921\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6548\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8400\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8800\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  5.94it/s]\n",
      "Epoch 4 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 206626.6309\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 206626.6309\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6790\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6115\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8808\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8800\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:18<00:00,  5.49it/s]\n",
      "Epoch 5 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 206805.0410\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 206805.0410\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5443\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5840\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8800\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.61it/s]\n",
      "Epoch 6 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 206976.5742\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 206976.5742\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4525\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3604\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9150\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9400\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.69it/s]\n",
      "Epoch 7 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 207150.5283\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 207150.5283\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3866\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3295\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9242\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9400\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.87it/s]\n",
      "Epoch 8 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 207326.0449\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 207326.0449\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3370\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2258\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9348\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9800\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.87it/s]\n",
      "Epoch 9 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 207503.3848\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 207503.3848\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2989\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2070\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9430\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9800\n",
      "-- >> End of training phase << --\n",
      "End training on experience 0\n",
      "Computing accuracy on the test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.60it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 207521.4629\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3258\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9300\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.28it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 207534.9277\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 7.5449\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.64it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 207548.1865\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 7.5152\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.41it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 207562.4434\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.0404\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.60it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 207575.8691\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 7.1742\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.22it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp005 = 207589.2354\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 7.2031\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- Starting eval on experience 6 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.59it/s]\n",
      "> Eval on experience 6 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp006 = 207603.6133\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp006 = 7.2652\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.0000\n",
      "-- Starting eval on experience 7 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.51it/s]\n",
      "> Eval on experience 7 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp007 = 207616.7168\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp007 = 7.8193\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.0000\n",
      "-- Starting eval on experience 8 (Task 0) from test stream --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.39it/s]\n",
      "> Eval on experience 8 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp008 = 207629.7979\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp008 = 6.9010\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.0000\n",
      "-- Starting eval on experience 9 (Task 0) from test stream --\n",
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.05it/s]\n",
      "> Eval on experience 9 (Task 0) from test stream ended.\n",
      "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp009 = 207640.0049\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp009 = 6.9569\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tConfusionMatrix_Stream/eval_phase/test_stream = <avalanche.evaluation.metric_results.AlternativeValues object at 0x7fd8f3f80df0>\n",
      "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 207640.0049\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.6746\n",
      "\tStreamBWT/eval_phase/test_stream = 0.0000\n",
      "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0930\n",
      "Start training on experience  1\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.59it/s]\n",
      "Epoch 0 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 207909.6650\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 207909.6650\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.6562\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2643\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0598\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2000\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:22<00:00,  4.51it/s]\n",
      "Epoch 1 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 208087.3047\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 208087.3047\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4017\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6384\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4364\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6400\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.61it/s]\n",
      "Epoch 2 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 208272.7891\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 208272.7891\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3979\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1845\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7040\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7200\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.66it/s]\n",
      "Epoch 3 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 208446.3564\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 208446.3564\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9742\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9699\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7948\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:20<00:00,  4.78it/s]\n",
      "Epoch 4 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 208622.5674\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 208622.5674\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7656\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7311\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8322\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.73it/s]\n",
      "Epoch 5 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 208799.7930\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 208799.7930\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6405\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4409\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8586\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9000\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.74it/s]\n",
      "Epoch 6 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 208975.8389\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 208975.8389\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5560\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5046\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8706\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9000\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.70it/s]\n",
      "Epoch 7 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 209149.7637\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 209149.7637\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4947\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4696\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8854\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8800\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.62it/s]\n",
      "Epoch 8 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 209330.0508\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 209330.0508\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4472\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3951\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8928\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9000\n",
      "100%|██████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.69it/s]\n",
      "Epoch 9 ended.\n",
      "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 209507.4365\n",
      "\tDiskUsage_MB/train_phase/train_stream/Task000 = 209507.4365\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4092\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3760\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8992\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9000\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start training on experience \", experience.current_experience)\n",
    "\n",
    "    cl_strategy.train(experience)\n",
    "    print(\"End training on experience\", experience.current_experience)\n",
    "    print(\"Computing accuracy on the test set\")\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream[:]))\n",
    "        \n",
    "        \n",
    "# for experience in benchmark.train_stream:\n",
    "#     # train returns a dictionary which contains all the metric values\n",
    "#     res = cl_strategy.train(experience)\n",
    "#     print('Training completed')\n",
    "\n",
    "#     print('Computing accuracy on the whole test set')\n",
    "    # test also returns a dictionary which contains all the metric values\n",
    "#     results.append(cl_strategy.eval(benchmark.test_stream))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b16565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8fc823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fedconlearn] *",
   "language": "python",
   "name": "conda-env-fedconlearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
