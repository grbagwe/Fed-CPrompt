{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475ad4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grbagwe/miniconda3/envs/promptFCL/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "# module_path = os.path.abspath(os.path.join('../../Prompt-based-class-incremental-learning-in-Federated-Learning/CODA_Prompt_CVPR2023_Code/'))\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import torch, torchvision, numpy as np\n",
    "from dataloaders import dataloader\n",
    "from dataloaders.dataloader import iCIFAR100_Fed\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbfea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5bc0188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks = []\n",
    "tasks_logits = []\n",
    "p = 0\n",
    "max_task = -1\n",
    "other_split_size = 10 \n",
    "first_split_size = 10 \n",
    "num_classes = 100 \n",
    "class_order = np.arange(num_classes).tolist()\n",
    "class_order_logits = np.arange(num_classes).tolist()\n",
    "rand_split = True\n",
    "\n",
    "if seed > 0 and rand_split:\n",
    "    print('=============================================')\n",
    "    print('Shuffling....')\n",
    "    print('pre-shuffle:' + str(class_order))\n",
    "    random.seed(seed)\n",
    "    random.shuffle(class_order)\n",
    "    print('post-shuffle:' + str(class_order))\n",
    "    print('=============================================')\n",
    "            \n",
    "            \n",
    "while p < num_classes and (max_task == -1 or len(tasks) < max_task):\n",
    "    inc = other_split_size if p > 0 else first_split_size\n",
    "    tasks.append(class_order[p:p + inc])\n",
    "    tasks_logits.append(class_order_logits[p:p + inc])\n",
    "    p += inc\n",
    "num_tasks = len(tasks)\n",
    "task_names = [str(i + 1) for i in range(num_tasks)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f1a66ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       " [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       " [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       " [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       " [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       " [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       " [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       " [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ddfd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Validation is true\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import dataloaders\n",
    "train_transform = dataloaders.utils.get_transform(dataset='CIFAR100_Fed', phase='train', aug=True,\n",
    "                                                    resize_imnet=True)\n",
    "test_transform = dataloaders.utils.get_transform(dataset='CIFAR100_Fed', phase='test', aug=True,\n",
    "                                                    resize_imnet=True)\n",
    "\n",
    "val_dataset = dataloader.iCIFAR100_Fed(root= \"data\", train = False,\n",
    "                                         num_clients = 10,\n",
    "                                         iid  = 0, \n",
    "                                        download_Flag = True,\n",
    "                                        validation=True, transform=test_transform,\n",
    "                                         tasks=tasks, seed=0\n",
    "                                        )\n",
    "train_dataset = dataloader.iCIFAR100_Fed(root= \"data\", train = True,\n",
    "                                         num_clients = 10,\n",
    "                                         iid  = 0, \n",
    "                                        download_Flag = True,\n",
    "                                        validation=False, transform=train_transform,\n",
    "                                         tasks=tasks, seed=0\n",
    "                                        )\n",
    "\n",
    "test_dataset = dataloader.iCIFAR100_Fed(root= \"data\", train = False,\n",
    "                                         num_clients = 10,\n",
    "                                         iid  = 0, \n",
    "                                        download_Flag = True,\n",
    "                                        validation=False, transform=test_transform,\n",
    "                                         tasks=tasks, seed=0\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a803c1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 32, 32, 3), (5000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape, val_dataset.data.shape, test_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc277c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.load_dataset(t= 7, client=-1)\n",
    "# len(train_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4497a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets in dataloader [20 21 22 23 24 25 26 27 28 29]\n"
     ]
    }
   ],
   "source": [
    "test_dataset.load_dataset(t = 2,train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11b0e400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e49114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loader for task 0\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "# train_dataset.load_dataset(t = 0,train = True, client=1)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7e0616aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++ in feature+++++++++++++++++++++\n",
      " freezing original model\n",
      "freezing cls_token\n",
      "freezing pos_embed\n",
      "freezing patch_embed.proj.weight\n",
      "freezing patch_embed.proj.bias\n",
      "freezing blocks.0.norm1.weight\n",
      "freezing blocks.0.norm1.bias\n",
      "freezing blocks.0.attn.qkv.weight\n",
      "freezing blocks.0.attn.qkv.bias\n",
      "freezing blocks.0.attn.proj.weight\n",
      "freezing blocks.0.attn.proj.bias\n",
      "freezing blocks.0.norm2.weight\n",
      "freezing blocks.0.norm2.bias\n",
      "freezing blocks.0.mlp.fc1.weight\n",
      "freezing blocks.0.mlp.fc1.bias\n",
      "freezing blocks.0.mlp.fc2.weight\n",
      "freezing blocks.0.mlp.fc2.bias\n",
      "freezing blocks.1.norm1.weight\n",
      "freezing blocks.1.norm1.bias\n",
      "freezing blocks.1.attn.qkv.weight\n",
      "freezing blocks.1.attn.qkv.bias\n",
      "freezing blocks.1.attn.proj.weight\n",
      "freezing blocks.1.attn.proj.bias\n",
      "freezing blocks.1.norm2.weight\n",
      "freezing blocks.1.norm2.bias\n",
      "freezing blocks.1.mlp.fc1.weight\n",
      "freezing blocks.1.mlp.fc1.bias\n",
      "freezing blocks.1.mlp.fc2.weight\n",
      "freezing blocks.1.mlp.fc2.bias\n",
      "freezing blocks.2.norm1.weight\n",
      "freezing blocks.2.norm1.bias\n",
      "freezing blocks.2.attn.qkv.weight\n",
      "freezing blocks.2.attn.qkv.bias\n",
      "freezing blocks.2.attn.proj.weight\n",
      "freezing blocks.2.attn.proj.bias\n",
      "freezing blocks.2.norm2.weight\n",
      "freezing blocks.2.norm2.bias\n",
      "freezing blocks.2.mlp.fc1.weight\n",
      "freezing blocks.2.mlp.fc1.bias\n",
      "freezing blocks.2.mlp.fc2.weight\n",
      "freezing blocks.2.mlp.fc2.bias\n",
      "freezing blocks.3.norm1.weight\n",
      "freezing blocks.3.norm1.bias\n",
      "freezing blocks.3.attn.qkv.weight\n",
      "freezing blocks.3.attn.qkv.bias\n",
      "freezing blocks.3.attn.proj.weight\n",
      "freezing blocks.3.attn.proj.bias\n",
      "freezing blocks.3.norm2.weight\n",
      "freezing blocks.3.norm2.bias\n",
      "freezing blocks.3.mlp.fc1.weight\n",
      "freezing blocks.3.mlp.fc1.bias\n",
      "freezing blocks.3.mlp.fc2.weight\n",
      "freezing blocks.3.mlp.fc2.bias\n",
      "freezing blocks.4.norm1.weight\n",
      "freezing blocks.4.norm1.bias\n",
      "freezing blocks.4.attn.qkv.weight\n",
      "freezing blocks.4.attn.qkv.bias\n",
      "freezing blocks.4.attn.proj.weight\n",
      "freezing blocks.4.attn.proj.bias\n",
      "freezing blocks.4.norm2.weight\n",
      "freezing blocks.4.norm2.bias\n",
      "freezing blocks.4.mlp.fc1.weight\n",
      "freezing blocks.4.mlp.fc1.bias\n",
      "freezing blocks.4.mlp.fc2.weight\n",
      "freezing blocks.4.mlp.fc2.bias\n",
      "freezing blocks.5.norm1.weight\n",
      "freezing blocks.5.norm1.bias\n",
      "freezing blocks.5.attn.qkv.weight\n",
      "freezing blocks.5.attn.qkv.bias\n",
      "freezing blocks.5.attn.proj.weight\n",
      "freezing blocks.5.attn.proj.bias\n",
      "freezing blocks.5.norm2.weight\n",
      "freezing blocks.5.norm2.bias\n",
      "freezing blocks.5.mlp.fc1.weight\n",
      "freezing blocks.5.mlp.fc1.bias\n",
      "freezing blocks.5.mlp.fc2.weight\n",
      "freezing blocks.5.mlp.fc2.bias\n",
      "freezing blocks.6.norm1.weight\n",
      "freezing blocks.6.norm1.bias\n",
      "freezing blocks.6.attn.qkv.weight\n",
      "freezing blocks.6.attn.qkv.bias\n",
      "freezing blocks.6.attn.proj.weight\n",
      "freezing blocks.6.attn.proj.bias\n",
      "freezing blocks.6.norm2.weight\n",
      "freezing blocks.6.norm2.bias\n",
      "freezing blocks.6.mlp.fc1.weight\n",
      "freezing blocks.6.mlp.fc1.bias\n",
      "freezing blocks.6.mlp.fc2.weight\n",
      "freezing blocks.6.mlp.fc2.bias\n",
      "freezing blocks.7.norm1.weight\n",
      "freezing blocks.7.norm1.bias\n",
      "freezing blocks.7.attn.qkv.weight\n",
      "freezing blocks.7.attn.qkv.bias\n",
      "freezing blocks.7.attn.proj.weight\n",
      "freezing blocks.7.attn.proj.bias\n",
      "freezing blocks.7.norm2.weight\n",
      "freezing blocks.7.norm2.bias\n",
      "freezing blocks.7.mlp.fc1.weight\n",
      "freezing blocks.7.mlp.fc1.bias\n",
      "freezing blocks.7.mlp.fc2.weight\n",
      "freezing blocks.7.mlp.fc2.bias\n",
      "freezing blocks.8.norm1.weight\n",
      "freezing blocks.8.norm1.bias\n",
      "freezing blocks.8.attn.qkv.weight\n",
      "freezing blocks.8.attn.qkv.bias\n",
      "freezing blocks.8.attn.proj.weight\n",
      "freezing blocks.8.attn.proj.bias\n",
      "freezing blocks.8.norm2.weight\n",
      "freezing blocks.8.norm2.bias\n",
      "freezing blocks.8.mlp.fc1.weight\n",
      "freezing blocks.8.mlp.fc1.bias\n",
      "freezing blocks.8.mlp.fc2.weight\n",
      "freezing blocks.8.mlp.fc2.bias\n",
      "freezing blocks.9.norm1.weight\n",
      "freezing blocks.9.norm1.bias\n",
      "freezing blocks.9.attn.qkv.weight\n",
      "freezing blocks.9.attn.qkv.bias\n",
      "freezing blocks.9.attn.proj.weight\n",
      "freezing blocks.9.attn.proj.bias\n",
      "freezing blocks.9.norm2.weight\n",
      "freezing blocks.9.norm2.bias\n",
      "freezing blocks.9.mlp.fc1.weight\n",
      "freezing blocks.9.mlp.fc1.bias\n",
      "freezing blocks.9.mlp.fc2.weight\n",
      "freezing blocks.9.mlp.fc2.bias\n",
      "freezing blocks.10.norm1.weight\n",
      "freezing blocks.10.norm1.bias\n",
      "freezing blocks.10.attn.qkv.weight\n",
      "freezing blocks.10.attn.qkv.bias\n",
      "freezing blocks.10.attn.proj.weight\n",
      "freezing blocks.10.attn.proj.bias\n",
      "freezing blocks.10.norm2.weight\n",
      "freezing blocks.10.norm2.bias\n",
      "freezing blocks.10.mlp.fc1.weight\n",
      "freezing blocks.10.mlp.fc1.bias\n",
      "freezing blocks.10.mlp.fc2.weight\n",
      "freezing blocks.10.mlp.fc2.bias\n",
      "freezing blocks.11.norm1.weight\n",
      "freezing blocks.11.norm1.bias\n",
      "freezing blocks.11.attn.qkv.weight\n",
      "freezing blocks.11.attn.qkv.bias\n",
      "freezing blocks.11.attn.proj.weight\n",
      "freezing blocks.11.attn.proj.bias\n",
      "freezing blocks.11.norm2.weight\n",
      "freezing blocks.11.norm2.bias\n",
      "freezing blocks.11.mlp.fc1.weight\n",
      "freezing blocks.11.mlp.fc1.bias\n",
      "freezing blocks.11.mlp.fc2.weight\n",
      "freezing blocks.11.mlp.fc2.bias\n",
      "freezing norm.weight\n",
      "freezing norm.bias\n",
      " in CODA prompt\n",
      "ortho_mu  0\n"
     ]
    }
   ],
   "source": [
    "# load model \n",
    "from models.vit_coda_p import vit_pt_imnet\n",
    "prompt_params = [10, [100, 8, 0 ,0 ,0]]\n",
    "model_codap = vit_pt_imnet(out_dim=100, prompt_flag = 'codap', prompt_param=prompt_params)\n",
    "st1 = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/niid_embedding_scaledtrilplet/models/repeat-1/task-10/class.pth\")\n",
    "st2 = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/niid_embedding_scaledtrilplet/models/repeat-1/task-3/class.pth\")\n",
    "\n",
    "st1_iid = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/iid/models/repeat-1/task-10/class.pth\")\n",
    "st2_iid = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/iid/models/repeat-1/task-3/class.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "64881110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "model1 = copy.deepcopy(model_codap)\n",
    "model2 = copy.deepcopy(model_codap)\n",
    "model1 = torch.nn.DataParallel(model1)\n",
    "model2 = torch.nn.DataParallel(model2)\n",
    "# model1.cuda(), model2.cuda()\n",
    "model1.cuda()\n",
    "model2.cuda()\n",
    "\n",
    "model1.load_state_dict(st1)\n",
    "model2.load_state_dict(st2)\n",
    "model_1_iid = copy.deepcopy(model_codap)\n",
    "model_2_iid = copy.deepcopy(model_codap)\n",
    "model_1_iid = torch.nn.DataParallel(model_1_iid)\n",
    "model_2_iid = torch.nn.DataParallel(model_2_iid)\n",
    "# model1.cuda(), model2.cuda()\n",
    "model_1_iid.cuda()\n",
    "model_2_iid.cuda()\n",
    "model_1_iid.load_state_dict(st1_iid)\n",
    "model_2_iid.load_state_dict(st2_iid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9f1dd44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23, 76, 21, 20, 94, 24, 22, 80, 85, 29, 22, 32, 21, 85, 80, 86, 76, 53,\n",
      "        94, 21, 23, 24, 90, 94, 99, 22, 93, 28, 24, 24, 71, 80, 24, 23, 24, 21,\n",
      "        40, 55, 28, 40, 29, 26, 80, 80, 80, 27, 94, 80, 91, 22, 22, 76, 26, 27,\n",
      "        76, 40, 90, 27, 80, 57, 50, 76, 61, 45, 87, 24, 87, 22, 26, 78, 28, 21,\n",
      "        76, 93, 93, 21, 21, 25, 90, 24, 22, 80, 55, 71, 76, 57, 84, 21, 24, 24,\n",
      "        22, 84, 57, 26, 40, 21, 21, 76, 76, 71, 23, 57, 24, 84, 90, 80, 80, 21,\n",
      "        81, 54, 76, 26, 66, 23, 88, 84, 28, 20, 71, 79, 64, 94, 57, 76, 21, 94,\n",
      "        71, 70], device='cuda:0') tensor([23, 29, 21, 20, 25, 24, 22, 27, 22, 29, 22, 27, 21, 21, 26, 25, 20, 27,\n",
      "        20, 21, 23, 24, 25, 20, 24, 22, 28, 28, 24, 24, 23, 27, 24, 23, 24, 21,\n",
      "        28, 27, 28, 28, 29, 26, 21, 27, 29, 27, 27, 27, 26, 22, 22, 22, 26, 27,\n",
      "        25, 25, 29, 27, 27, 26, 25, 20, 28, 26, 22, 24, 20, 22, 26, 22, 28, 21,\n",
      "        25, 26, 29, 21, 21, 25, 25, 24, 22, 29, 23, 22, 25, 26, 20, 21, 24, 24,\n",
      "        22, 20, 29, 26, 28, 21, 21, 22, 23, 23, 23, 28, 24, 21, 25, 29, 27, 21,\n",
      "        28, 26, 20, 26, 29, 23, 26, 25, 28, 20, 23, 29, 29, 25, 26, 25, 21, 25,\n",
      "        23, 28], device='cuda:0')\n",
      "acc 0.4140625\n",
      "preds_2 tensor([23, 29, 21, 20, 25, 24, 22, 27, 22, 29, 22, 10, 21, 21, 26, 25, 20, 27,\n",
      "        20, 21, 23, 24, 22, 20, 24, 22, 28, 28, 24, 24, 23, 27, 24, 23, 24, 21,\n",
      "        28, 27, 28, 28, 29, 26, 25, 27, 29, 27, 25, 27, 26, 22, 22, 22, 26, 27,\n",
      "        25, 25, 29, 27, 27, 26, 20, 20, 10, 26, 22, 24, 20, 22, 26, 22, 28, 21,\n",
      "        25, 26, 29, 21, 21, 25, 20, 24, 22, 29, 23, 22, 25, 26, 20, 21, 24, 24,\n",
      "        22, 20, 29, 26, 28, 21, 21, 22, 23, 23, 23, 28, 24, 21, 25, 29, 27, 21,\n",
      "        28, 26, 20, 26, 29, 23, 26, 20, 28, 20, 23, 29, 26, 25, 26, 25, 21, 25,\n",
      "        23, 28], device='cuda:0')\n",
      "preds_iid_1 tensor([23, 29, 21, 20,  5, 24, 22, 27, 22, 29, 22, 32, 21, 21, 26, 25, 20, 27,\n",
      "        20, 21, 23, 24, 58, 20, 24, 22, 28, 28, 24, 24, 71, 27, 24, 23, 24, 21,\n",
      "        28, 27, 28, 28, 29, 26, 43, 27, 29, 27, 94, 27, 79, 22, 22, 22, 26, 27,\n",
      "         5, 40, 29, 27, 27, 26, 93, 20, 10, 45, 22, 24, 20, 22, 26, 22, 28, 21,\n",
      "        25, 26, 29, 21, 21, 25, 37, 24, 22, 29, 23, 22, 25, 26, 25, 21, 24, 24,\n",
      "        22, 20, 29, 26, 28, 21, 21, 22, 49, 71, 23, 28, 24, 21, 25, 29, 27, 21,\n",
      "        46, 26, 20, 26, 29, 23, 26, 25, 28, 20, 23, 15, 79, 25, 45, 76, 21, 25,\n",
      "        23, 28], device='cuda:0')\n",
      "preds_iid_2 tensor([23, 29, 21, 20,  5, 24, 22, 27, 22, 29, 22, 10, 21, 21, 26, 25, 20, 27,\n",
      "        20, 21, 23, 24, 13, 20, 24, 22, 28, 28, 24, 24, 23, 27, 24, 23, 24, 21,\n",
      "        28, 27, 28, 28, 29, 26,  4, 27, 29, 27, 25, 27, 14, 22, 22, 22, 26, 27,\n",
      "         5, 25, 29, 27, 27, 26, 20, 20, 10, 26, 22, 24, 20, 22, 26, 22, 28, 21,\n",
      "        25, 26, 29, 21, 21, 25, 20, 24, 22, 29, 23, 22, 25, 26, 25, 21, 24, 24,\n",
      "        22, 20, 29, 26, 28, 21, 21, 22, 23, 23, 23, 28, 24, 21, 25, 29, 27, 21,\n",
      "        28, 26, 20, 26, 29, 23, 26, 25, 28, 20, 23, 15, 29, 25, 26,  5, 21, 25,\n",
      "        23, 28], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        logits1_1, _, pre_logits_1, q_1 = model1(images, train = True)\n",
    "        logits1_2, _, pre_logits_2,q_2 = model2(images, train = True)\n",
    "        logits1_iid_1, _, pre_logits_iid_1, q_iid_1 = model_1_iid(images, train = True)\n",
    "        logits1_iid_2, _, pre_logits_iid_2,q_iid_2 = model_2_iid(images, train = True)\n",
    "\n",
    "        logits1 = logits1_1\n",
    "        logits_og = logits1\n",
    "        # logits2 = model2(images)\n",
    "        # logits = (logits1 + logits2)/2\n",
    "        # logits1 = logits1[:,:30]\n",
    "        logits = logits1\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        _, preds_2 = torch.max(logits1_2[:,0:30], 1)\n",
    "        _, preds_iid_1 = torch.max(logits1_iid_1, 1)\n",
    "        _, preds_iid_2 = torch.max(logits1_iid_2[:,0:30], 1)\n",
    "\n",
    "\n",
    "        # add 20 to preds\n",
    "        # preds = preds + 20\n",
    "        acc = torch.sum(preds == labels).item() / labels.size(0)\n",
    "        print(preds, labels)\n",
    "\n",
    "        print(\"acc\", acc)\n",
    "        print( \"preds_2\", preds_2)\n",
    "        print(\"preds_iid_1\", preds_iid_1)\n",
    "        print(\"preds_iid_2\", preds_iid_2)\n",
    "        \n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b0f796da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0605e-05, device='cuda:0')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(pre_logits_1[0] - pre_logits_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "582ecf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.module.last.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "73ee5a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.6294, -11.8294, -10.5037,  -7.3202,  -9.3172, -10.3681,  -9.5813,\n",
       "        -11.0830,  -7.6190, -10.4965,  -7.8101,  -9.3435,  -5.7949, -10.1437,\n",
       "        -10.2441,  -9.2260, -10.2589,  -8.3527, -10.0273,  -8.8415,  -7.0708,\n",
       "         -9.0371,  -7.2863,  -0.1060,  -8.6623,  -6.9183,  -7.7822,  -7.4883,\n",
       "         -8.1351,  -5.6652,  -6.9498,  -6.0662,  -5.7977,  -5.0095,  -7.5059,\n",
       "         -6.3690,  -6.9743,  -5.1180,  -7.6109,  -9.2761,  -5.7314,  -7.6933,\n",
       "         -5.8939,  -7.1541,  -7.1225,  -7.6397,  -5.6529,  -5.8227,  -6.4950,\n",
       "         -2.1985,  -5.6417,  -6.9338,  -4.4371,  -7.1126,  -6.1104,  -5.0639,\n",
       "         -4.4474,  -5.4188,  -5.5585,  -3.0155,  -2.3967,  -6.2424,  -7.5332,\n",
       "         -5.0690,  -5.1382,  -5.9561,  -5.7224,  -5.3951,  -4.6591,  -2.8164,\n",
       "         -4.6695,  -0.3929,  -4.0758,  -4.1713,  -5.2894,  -4.1033,  -1.4858,\n",
       "         -4.9136,  -4.6274,  -5.7346,  -3.8827,  -3.1228,  -5.3784,  -5.3027,\n",
       "         -4.2971,  -4.0749,  -3.6755,  -2.5925,  -3.9997,  -3.6038,  -3.3625,\n",
       "         -4.3426,  -5.2592,  -4.1689,  -5.5633,  -3.4258,  -3.4105,  -4.4644,\n",
       "         -4.6643,  -4.5734], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.module.last(pre_logits_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "696a38e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.6294, -11.8295, -10.5037,  -7.3202,  -9.3172, -10.3681,  -9.5813,\n",
       "        -11.0830,  -7.6190, -10.4966,  -7.8101,  -9.3435,  -5.7949, -10.1437,\n",
       "        -10.2441,  -9.2261, -10.2590,  -8.3527, -10.0273,  -8.8415,  -7.0574,\n",
       "         -9.0469,  -7.2878,  -0.1403,  -8.6337,  -6.9298,  -7.7318,  -7.4513,\n",
       "         -8.1479,  -5.5823,  -0.7606,   2.4150,  -0.5042,  -0.2146,  -0.2253,\n",
       "          0.7207,   1.2957,  -0.3528,  -0.6998,   0.2035,  -0.3755,  -0.6595,\n",
       "          1.5844,   0.2050,  -0.3879,  -1.6829,  -0.6330,  -0.2186,   0.3370,\n",
       "          0.9689,  -0.5870,  -2.8442,   0.1528,   0.6425,  -0.3888,  -0.7800,\n",
       "         -0.2022,   1.4043,  -0.0192,   1.8707,   0.6996,   0.8951,  -0.9157,\n",
       "          1.8459,   1.0750,  -0.3175,  -0.4730,   0.5669,  -1.5238,   0.0884,\n",
       "          1.4296,  -0.7932,   0.4535,  -1.0342,  -1.0681,   1.2281,   1.5558,\n",
       "          1.3616,   1.0175,   0.2455,   0.0122,  -1.0005,  -1.6178,   0.0300,\n",
       "         -0.6465,  -0.6134,   0.2200,   0.8564,   1.2809,   0.4481,  -0.7573,\n",
       "          0.8844,   0.7579,   1.9536,  -1.3094,   0.5975,  -0.7683,  -0.4228,\n",
       "          0.6516,   0.0213], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.module.last(pre_logits_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1243a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.module.last.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e207a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_logits_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9ad38059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23, device='cuda:0')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model1.module.last(pre_logits_2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2a99500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23, device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model2.module.last(pre_logits_1[0])[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "af9d0733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(23, device='cuda:0'),\n",
       " tensor(23, device='cuda:0'),\n",
       " tensor(29, device='cuda:0'))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0], torch.argmax(logits1_1[0]), torch.argmax(logits1_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8c105a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "keys_st1 = st1['module.prompt.e_k_0']\n",
    "p = st1['module.prompt.e_p_0']\n",
    "\n",
    "\n",
    "q_norm = nn.functional.normalize(q_, dim=1)\n",
    "n_K = nn.functional.normalize(keys_st1, dim=1)\n",
    "aq_k = torch.einsum('bd,kd->bk', q_norm.cuda(), n_K.cuda())\n",
    "P_ = torch.einsum('bk,kld->bld', aq_k.cuda(), p.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4338a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, indices = torch.topk(torch.sum(aq_k, dim=0), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4a6979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0008, device='cuda:0')\n",
      "tensor(0.0117, device='cuda:0')\n",
      "tensor(-0.0635, device='cuda:0')\n",
      "tensor(0.0255, device='cuda:0')\n",
      "tensor(-0.0317, device='cuda:0')\n",
      "tensor(-0.0361, device='cuda:0')\n",
      "tensor(-0.0272, device='cuda:0')\n",
      "tensor(-0.0453, device='cuda:0')\n",
      "tensor(0.0472, device='cuda:0')\n",
      "tensor(-0.0236, device='cuda:0')\n",
      "tensor(0.0522, device='cuda:0')\n",
      "tensor(0.0828, device='cuda:0')\n",
      "tensor(0.0071, device='cuda:0')\n",
      "tensor(-0.0496, device='cuda:0')\n",
      "tensor(-0.0027, device='cuda:0')\n",
      "tensor(-0.0465, device='cuda:0')\n",
      "tensor(0.0026, device='cuda:0')\n",
      "tensor(-0.0321, device='cuda:0')\n",
      "tensor(0.0247, device='cuda:0')\n",
      "tensor(0.0422, device='cuda:0')\n",
      "tensor(-0.0445, device='cuda:0')\n",
      "tensor(-0.0107, device='cuda:0')\n",
      "tensor(0.0294, device='cuda:0')\n",
      "tensor(-0.0008, device='cuda:0')\n",
      "tensor(0.0010, device='cuda:0')\n",
      "tensor(-0.0607, device='cuda:0')\n",
      "tensor(-0.0114, device='cuda:0')\n",
      "tensor(0.0368, device='cuda:0')\n",
      "tensor(-0.0017, device='cuda:0')\n",
      "tensor(-0.0336, device='cuda:0')\n",
      "tensor(0.0821, device='cuda:0')\n",
      "tensor(0.0097, device='cuda:0')\n",
      "tensor(-0.0174, device='cuda:0')\n",
      "tensor(-0.0279, device='cuda:0')\n",
      "tensor(-0.0143, device='cuda:0')\n",
      "tensor(-0.0436, device='cuda:0')\n",
      "tensor(-0.0186, device='cuda:0')\n",
      "tensor(0.0395, device='cuda:0')\n",
      "tensor(0.0218, device='cuda:0')\n",
      "tensor(0.0047, device='cuda:0')\n",
      "tensor(0.0364, device='cuda:0')\n",
      "tensor(-0.0460, device='cuda:0')\n",
      "tensor(0.0551, device='cuda:0')\n",
      "tensor(-0.0021, device='cuda:0')\n",
      "tensor(0.0242, device='cuda:0')\n",
      "tensor(-0.0417, device='cuda:0')\n",
      "tensor(0.0271, device='cuda:0')\n",
      "tensor(0.0122, device='cuda:0')\n",
      "tensor(-0.0565, device='cuda:0')\n",
      "tensor(-0.0206, device='cuda:0')\n",
      "tensor(0.0084, device='cuda:0')\n",
      "tensor(0.0330, device='cuda:0')\n",
      "tensor(-0.0315, device='cuda:0')\n",
      "tensor(-0.0246, device='cuda:0')\n",
      "tensor(0.0219, device='cuda:0')\n",
      "tensor(-0.0139, device='cuda:0')\n",
      "tensor(-0.0177, device='cuda:0')\n",
      "tensor(-0.0149, device='cuda:0')\n",
      "tensor(0.0614, device='cuda:0')\n",
      "tensor(0.0017, device='cuda:0')\n",
      "tensor(0.0149, device='cuda:0')\n",
      "tensor(0.0602, device='cuda:0')\n",
      "tensor(0.0516, device='cuda:0')\n",
      "tensor(0.0041, device='cuda:0')\n",
      "tensor(0.0522, device='cuda:0')\n",
      "tensor(-0.0198, device='cuda:0')\n",
      "tensor(0.0269, device='cuda:0')\n",
      "tensor(-0.0298, device='cuda:0')\n",
      "tensor(0.0025, device='cuda:0')\n",
      "tensor(-0.0134, device='cuda:0')\n",
      "tensor(0.0066, device='cuda:0')\n",
      "tensor(-0.0447, device='cuda:0')\n",
      "tensor(0.0404, device='cuda:0')\n",
      "tensor(-0.0021, device='cuda:0')\n",
      "tensor(0.0247, device='cuda:0')\n",
      "tensor(0.0241, device='cuda:0')\n",
      "tensor(0.0218, device='cuda:0')\n",
      "tensor(-0.0338, device='cuda:0')\n",
      "tensor(0.0221, device='cuda:0')\n",
      "tensor(0.0029, device='cuda:0')\n",
      "tensor(-0.0454, device='cuda:0')\n",
      "tensor(0.0009, device='cuda:0')\n",
      "tensor(-0.0300, device='cuda:0')\n",
      "tensor(-0.0436, device='cuda:0')\n",
      "tensor(-0.0418, device='cuda:0')\n",
      "tensor(0.0292, device='cuda:0')\n",
      "tensor(-0.0073, device='cuda:0')\n",
      "tensor(0.0776, device='cuda:0')\n",
      "tensor(-0.0415, device='cuda:0')\n",
      "tensor(-0.0276, device='cuda:0')\n",
      "tensor(-0.0109, device='cuda:0')\n",
      "tensor(-0.0088, device='cuda:0')\n",
      "tensor(0.0469, device='cuda:0')\n",
      "tensor(0.0300, device='cuda:0')\n",
      "tensor(-0.0056, device='cuda:0')\n",
      "tensor(-0.0244, device='cuda:0')\n",
      "tensor(-0.0310, device='cuda:0')\n",
      "tensor(-0.0273, device='cuda:0')\n",
      "tensor(-0.0381, device='cuda:0')\n",
      "tensor(-0.0201, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "q_0 = q_[0].cuda()\n",
    "keys_st1 = keys_st1.cuda()\n",
    "sim_ind= []\n",
    "for i in range(100):\n",
    "    # torch.nn.CosineSimilarity(dim=0, eps=1e-6)(q_0, keys_st1[i])\n",
    "    print(torch.nn.CosineSimilarity(dim=0, eps=1e-6)(q_0, keys_st1[i]))\n",
    "    sim_ind.append(torch.nn.CosineSimilarity(dim=0, eps=1e-6)(q_0, keys_st1[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e1c5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "score , ind = torch.topk(torch.tensor(sim_ind), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14a6e30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 30, 87, 58, 61, 42, 10, 64, 62,  8])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6d993bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23, device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8443675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CosineSimilarity(dim=0, eps=1e-6)(q_0, keys_st1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "554a01f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 27\n",
      "58 25\n",
      "71 23\n",
      "43 21\n",
      "94 27\n",
      "79 26\n",
      "40 25\n",
      "93 25\n",
      "45 26\n",
      "37 25\n",
      "49 23\n",
      "71 23\n",
      "46 28\n",
      "79 29\n",
      "45 26\n",
      "76 25\n",
      "pred shape torch.Size([128])\n",
      "total_incorrect 21\n",
      "total_incorrect_g30 16\n"
     ]
    }
   ],
   "source": [
    "# print all the preds not equal to labels\n",
    "total_incorrect = 0\n",
    "total_incorrect_g30 = 0\n",
    "for i, pred in enumerate(preds):\n",
    "    if pred != labels[i]:\n",
    "        total_incorrect += 1\n",
    "        if pred >30:\n",
    "            print(pred.detach().cpu().numpy(), labels[i].detach().cpu().numpy())\n",
    "            total_incorrect_g30 += 1\n",
    "\n",
    "print(\"pred shape\", preds.shape)\n",
    "print(\"total_incorrect\", total_incorrect)\n",
    "\n",
    "print(\"total_incorrect_g30\", total_incorrect_g30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fb0c517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, indices = torch.topk(logits_og, 5, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5db300d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.5669, -2.9218, -3.7614, -3.8750, -3.9633], device='cuda:0'),\n",
       " tensor([57, 83, 70,  0, 90], device='cuda:0'))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0], indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9693cf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  8,  8,  4,  6,  9,  2,  7,  6,  0,  9,  8,  1, 51, 80,  8,  9,  4,\n",
      "         7,  6,  6,  2,  0,  0,  4,  6,  1,  6,  7,  8,  2,  6,  5,  9,  7, 24,\n",
      "         0,  6,  3,  6,  3,  2,  8,  2,  5,  9,  7,  5, 35,  6,  0,  8,  4, 83,\n",
      "         3,  2,  8,  6,  2,  8,  1,  2,  9, 92,  9,  3,  1,  4,  0,  0,  3,  8,\n",
      "         7,  0,  5,  1, 33,  1,  1,  7,  1,  0,  1,  3,  4,  8,  7,  7,  0,  1,\n",
      "         6,  6,  7,  6,  9,  1,  2,  8,  2,  9,  6,  3, 35,  9, 35,  0,  9,  1,\n",
      "         0,  3,  8,  6,  9,  2,  3,  7,  7,  1, 48,  4,  1,  1,  9,  9,  0,  5,\n",
      "         2,  2], device='cuda:0') \n",
      " tensor([0, 8, 8, 4, 6, 9, 2, 7, 6, 0, 9, 8, 1, 4, 4, 8, 9, 4, 7, 6, 6, 2, 0, 0,\n",
      "        4, 6, 1, 6, 7, 8, 2, 7, 5, 9, 7, 7, 0, 6, 3, 6, 3, 2, 8, 2, 5, 9, 7, 5,\n",
      "        2, 6, 0, 8, 4, 0, 3, 2, 8, 6, 2, 8, 1, 2, 9, 7, 9, 3, 1, 4, 0, 0, 3, 8,\n",
      "        7, 0, 5, 1, 6, 1, 1, 7, 1, 0, 1, 3, 4, 8, 7, 7, 0, 1, 6, 6, 7, 6, 9, 1,\n",
      "        2, 8, 2, 9, 6, 3, 2, 9, 2, 0, 9, 1, 0, 3, 8, 6, 9, 2, 3, 7, 7, 1, 8, 4,\n",
      "        1, 1, 9, 9, 0, 5, 2, 2], device='cuda:0')\n",
      "acc 0.9140625\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        logits1 = model1(images)\n",
    "        logits_og = logits1\n",
    "        # logits2 = model2(images)\n",
    "        # logits = (logits1 + logits2)/2\n",
    "        # logits1 = logits1[:,:10]\n",
    "        logits = logits1\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        acc = torch.sum(preds == labels).item() / labels.size(0)\n",
    "        print(preds,'\\n', labels)\n",
    "        print(\"acc\", acc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad2be92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -3.8750, -15.5412, -15.2822, -14.6839, -14.6898, -14.7954, -15.3071,\n",
       "        -16.0326, -17.0629, -14.9766,  -6.8506,  -9.8459, -12.8333, -12.6693,\n",
       "        -11.7477, -11.4122,  -9.4867, -13.6688, -13.6107, -11.1135,  -8.5984,\n",
       "        -10.5350,  -8.8834,  -7.9410,  -7.1641,  -9.2967,  -8.1881, -12.4823,\n",
       "         -6.8438, -10.4284,  -7.6836,  -7.3023,  -6.0095,  -5.9005,  -8.6389,\n",
       "         -7.2114,  -7.1643,  -5.4243,  -6.9239,  -9.1478,  -5.9899,  -6.6885,\n",
       "         -8.9336,  -9.7107,  -7.4439,  -7.7079,  -6.9071,  -8.7222,  -7.7159,\n",
       "         -8.8416,  -7.1582,  -7.1707,  -8.3464,  -4.8234,  -6.0594,  -6.5754,\n",
       "         -7.4814,  -2.5669,  -5.7630,  -8.7047,  -5.1122,  -5.3528,  -5.8680,\n",
       "         -6.5100,  -7.5326,  -5.0108,  -5.9449,  -5.7377,  -5.9489,  -4.3038,\n",
       "         -3.7614,  -6.1819,  -4.6122,  -5.9263,  -5.0056,  -5.9474,  -5.2399,\n",
       "         -5.4882,  -4.7142,  -5.8078,  -5.9321,  -6.4610,  -6.2589,  -2.9218,\n",
       "         -4.6292,  -6.3055,  -6.0599,  -4.9708,  -6.2679,  -7.3977,  -3.9633,\n",
       "         -7.1487,  -5.3933,  -5.2023,  -5.4656,  -6.0153,  -5.8533,  -5.4327,\n",
       "         -6.1531,  -6.2351], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_og[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d06e3373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.6379, -2.6649, -2.3945, -2.5460, -3.1054, -2.1626, -2.7818, -2.9526,\n",
       "        -4.5929, -0.3284,  3.6522, -0.4159, -4.4467, -3.8525, -2.4676, -3.1422,\n",
       "        -0.7572, -5.1269, -3.8622, -2.1604, -0.8472, -2.8972, -0.9772, -1.3567,\n",
       "         0.3898, -0.8054, -0.0911, -5.8205,  0.9100, -3.1022, -2.5422, -1.7781,\n",
       "         0.8788, -0.0671, -2.4871,  0.8180, -1.7161,  0.9883, -1.4391, -0.2957,\n",
       "         0.1015, -1.3130, -4.9796, -5.2192, -2.6978, -2.2231, -1.0323, -4.1772,\n",
       "        -2.3297, -5.1329, -2.6539, -2.6125, -4.7632,  1.7965, -1.5855, -2.1597,\n",
       "        -2.4876,  4.5060, -0.9806, -3.6072, -1.0290,  0.7408,  0.2772, -2.5698,\n",
       "        -2.1800, -0.2572, -1.2421, -1.7071, -2.9088,  0.9170,  0.9564, -2.7573,\n",
       "        -0.4826, -1.6642, -1.0925, -1.5364, -1.5310, -0.4942, -0.7283, -0.9050,\n",
       "        -2.6256, -3.2443, -2.4405,  2.6113, -0.1712, -3.5070, -1.6284, -1.9093,\n",
       "        -3.1675, -4.1349, -1.5294, -3.3422,  1.0541, -1.3605, -1.5730, -1.3621,\n",
       "        -2.0605, -2.0921, -0.3642, -1.9680], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_og[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3c0732c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.6379, device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(logits_og[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9170273f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dbbf99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_diff(st1, st2, key):\n",
    "    for i in range(100):\n",
    "     a= st1[key][i] - st2[key][i]\n",
    "     print( i , torch.round(torch.sum(a), decimals=5))\n",
    "    #  torch.round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ce5316e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-0.0008)\n",
      "1 tensor(0.0046)\n",
      "2 tensor(0.0023)\n",
      "3 tensor(-0.0019)\n",
      "4 tensor(0.0007)\n",
      "5 tensor(-0.0002)\n",
      "6 tensor(0.0009)\n",
      "7 tensor(0.0007)\n",
      "8 tensor(-0.0010)\n",
      "9 tensor(0.0064)\n",
      "10 tensor(-0.3351)\n",
      "11 tensor(-0.2483)\n",
      "12 tensor(-0.4482)\n",
      "13 tensor(-0.2832)\n",
      "14 tensor(-0.3512)\n",
      "15 tensor(-0.1289)\n",
      "16 tensor(-0.3490)\n",
      "17 tensor(-0.3591)\n",
      "18 tensor(-0.1321)\n",
      "19 tensor(-0.6878)\n",
      "20 tensor(0.)\n",
      "21 tensor(0.)\n",
      "22 tensor(-0.)\n",
      "23 tensor(-0.)\n",
      "24 tensor(-0.)\n",
      "25 tensor(-0.)\n",
      "26 tensor(0.)\n",
      "27 tensor(0.)\n",
      "28 tensor(-0.)\n",
      "29 tensor(-0.)\n",
      "30 tensor(-0.)\n",
      "31 tensor(-0.)\n",
      "32 tensor(0.)\n",
      "33 tensor(-0.)\n",
      "34 tensor(0.)\n",
      "35 tensor(0.)\n",
      "36 tensor(0.)\n",
      "37 tensor(0.)\n",
      "38 tensor(-0.)\n",
      "39 tensor(-0.)\n",
      "40 tensor(0.)\n",
      "41 tensor(0.)\n",
      "42 tensor(0.)\n",
      "43 tensor(0.)\n",
      "44 tensor(0.)\n",
      "45 tensor(-0.)\n",
      "46 tensor(0.)\n",
      "47 tensor(0.)\n",
      "48 tensor(-0.)\n",
      "49 tensor(-0.)\n",
      "50 tensor(-0.)\n",
      "51 tensor(0.)\n",
      "52 tensor(-0.)\n",
      "53 tensor(0.)\n",
      "54 tensor(0.)\n",
      "55 tensor(-0.)\n",
      "56 tensor(-0.)\n",
      "57 tensor(-0.)\n",
      "58 tensor(-0.)\n",
      "59 tensor(-0.)\n",
      "60 tensor(-0.)\n",
      "61 tensor(0.)\n",
      "62 tensor(0.)\n",
      "63 tensor(0.)\n",
      "64 tensor(0.)\n",
      "65 tensor(-0.)\n",
      "66 tensor(-0.)\n",
      "67 tensor(0.)\n",
      "68 tensor(-0.)\n",
      "69 tensor(0.)\n",
      "70 tensor(-0.)\n",
      "71 tensor(-0.)\n",
      "72 tensor(-0.)\n",
      "73 tensor(0.)\n",
      "74 tensor(-0.)\n",
      "75 tensor(0.)\n",
      "76 tensor(-0.)\n",
      "77 tensor(0.)\n",
      "78 tensor(-0.)\n",
      "79 tensor(0.)\n",
      "80 tensor(-0.)\n",
      "81 tensor(0.)\n",
      "82 tensor(0.)\n",
      "83 tensor(0.)\n",
      "84 tensor(0.)\n",
      "85 tensor(0.)\n",
      "86 tensor(0.)\n",
      "87 tensor(-0.)\n",
      "88 tensor(-0.)\n",
      "89 tensor(-0.)\n",
      "90 tensor(-0.)\n",
      "91 tensor(0.)\n",
      "92 tensor(0.)\n",
      "93 tensor(0.)\n",
      "94 tensor(-0.)\n",
      "95 tensor(-0.)\n",
      "96 tensor(0.)\n",
      "97 tensor(-0.)\n",
      "98 tensor(0.)\n",
      "99 tensor(-0.)\n"
     ]
    }
   ],
   "source": [
    "st1_c = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/niid_embedding_scaledtrilplet/models/repeat-1/task-1/class.pth\")\n",
    "st2_c = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/niid_embedding_scaledtrilplet/models/repeat-1/task-2/class.pth\")\n",
    "\n",
    "st1_iid_c = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/iid/models/repeat-1/task-1/class.pth\")\n",
    "st2_iid_c = torch.load(\"../_outputs/ICCV/CIFAR100/10-task/Fed-CPrompt/vit/iid/models/repeat-1/task-2/class.pth\")\n",
    "\n",
    "check_diff(st1_c, st2_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "592a6f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.0000e-05)\n",
      "1 tensor(0.)\n",
      "2 tensor(-0.)\n",
      "3 tensor(-0.)\n",
      "4 tensor(-0.)\n",
      "5 tensor(0.)\n",
      "6 tensor(-0.)\n",
      "7 tensor(0.)\n",
      "8 tensor(-1.0000e-05)\n",
      "9 tensor(-0.)\n",
      "10 tensor(-0.0569)\n",
      "11 tensor(0.0604)\n",
      "12 tensor(-0.0526)\n",
      "13 tensor(-0.1601)\n",
      "14 tensor(-0.0193)\n",
      "15 tensor(-0.1450)\n",
      "16 tensor(-0.1885)\n",
      "17 tensor(-0.1812)\n",
      "18 tensor(0.4209)\n",
      "19 tensor(-0.5322)\n",
      "20 tensor(0.)\n",
      "21 tensor(-0.)\n",
      "22 tensor(0.)\n",
      "23 tensor(-0.)\n",
      "24 tensor(-0.)\n",
      "25 tensor(-0.)\n",
      "26 tensor(-0.)\n",
      "27 tensor(-0.)\n",
      "28 tensor(0.)\n",
      "29 tensor(-0.)\n",
      "30 tensor(0.)\n",
      "31 tensor(0.)\n",
      "32 tensor(0.)\n",
      "33 tensor(0.)\n",
      "34 tensor(0.)\n",
      "35 tensor(0.)\n",
      "36 tensor(-0.)\n",
      "37 tensor(0.)\n",
      "38 tensor(0.)\n",
      "39 tensor(0.)\n",
      "40 tensor(-0.)\n",
      "41 tensor(-0.)\n",
      "42 tensor(-0.)\n",
      "43 tensor(-0.)\n",
      "44 tensor(-0.)\n",
      "45 tensor(-0.)\n",
      "46 tensor(0.)\n",
      "47 tensor(-0.)\n",
      "48 tensor(0.)\n",
      "49 tensor(0.)\n",
      "50 tensor(0.)\n",
      "51 tensor(-0.)\n",
      "52 tensor(-0.)\n",
      "53 tensor(0.)\n",
      "54 tensor(0.)\n",
      "55 tensor(0.)\n",
      "56 tensor(-0.)\n",
      "57 tensor(-0.)\n",
      "58 tensor(-0.)\n",
      "59 tensor(0.)\n",
      "60 tensor(-0.)\n",
      "61 tensor(-0.)\n",
      "62 tensor(0.)\n",
      "63 tensor(-0.)\n",
      "64 tensor(0.)\n",
      "65 tensor(-0.)\n",
      "66 tensor(0.)\n",
      "67 tensor(0.)\n",
      "68 tensor(-0.)\n",
      "69 tensor(-0.)\n",
      "70 tensor(0.)\n",
      "71 tensor(0.)\n",
      "72 tensor(0.)\n",
      "73 tensor(0.)\n",
      "74 tensor(0.)\n",
      "75 tensor(-0.)\n",
      "76 tensor(-0.)\n",
      "77 tensor(-0.)\n",
      "78 tensor(-0.)\n",
      "79 tensor(-0.)\n",
      "80 tensor(0.)\n",
      "81 tensor(0.)\n",
      "82 tensor(-0.)\n",
      "83 tensor(-0.)\n",
      "84 tensor(-0.)\n",
      "85 tensor(0.)\n",
      "86 tensor(0.)\n",
      "87 tensor(0.)\n",
      "88 tensor(-0.)\n",
      "89 tensor(0.)\n",
      "90 tensor(-0.)\n",
      "91 tensor(-0.)\n",
      "92 tensor(-0.)\n",
      "93 tensor(0.)\n",
      "94 tensor(-0.)\n",
      "95 tensor(-0.)\n",
      "96 tensor(-0.)\n",
      "97 tensor(-0.)\n",
      "98 tensor(-0.)\n",
      "99 tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "check_diff(st1_iid_c, st2_iid_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb1b3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_st1_c = st1_c['module.prompt.e_k_0']\n",
    "keys_st2_c = st2_c['module.prompt.e_k_0']\n",
    "keys_st1_iid_c = st1_iid_c['module.prompt.e_k_0']\n",
    "keys_st2_iid_c = st2_iid_c['module.prompt.e_k_0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8e506cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.)\n",
      "1 tensor(0.)\n",
      "2 tensor(0.)\n",
      "3 tensor(0.)\n",
      "4 tensor(0.)\n",
      "5 tensor(-0.)\n",
      "6 tensor(-0.)\n",
      "7 tensor(0.)\n",
      "8 tensor(-0.)\n",
      "9 tensor(0.)\n",
      "10 tensor(0.4761)\n",
      "11 tensor(0.1716)\n",
      "12 tensor(-0.3754)\n",
      "13 tensor(-0.2869)\n",
      "14 tensor(-0.3810)\n",
      "15 tensor(0.4018)\n",
      "16 tensor(0.4773)\n",
      "17 tensor(-0.5453)\n",
      "18 tensor(0.3002)\n",
      "19 tensor(0.5324)\n",
      "20 tensor(0.)\n",
      "21 tensor(-0.)\n",
      "22 tensor(-0.)\n",
      "23 tensor(0.)\n",
      "24 tensor(-0.)\n",
      "25 tensor(-0.)\n",
      "26 tensor(-0.)\n",
      "27 tensor(-0.)\n",
      "28 tensor(0.)\n",
      "29 tensor(-0.)\n",
      "30 tensor(0.)\n",
      "31 tensor(-0.)\n",
      "32 tensor(-0.)\n",
      "33 tensor(-0.)\n",
      "34 tensor(0.)\n",
      "35 tensor(0.)\n",
      "36 tensor(0.)\n",
      "37 tensor(0.)\n",
      "38 tensor(0.)\n",
      "39 tensor(-0.)\n",
      "40 tensor(-0.)\n",
      "41 tensor(0.)\n",
      "42 tensor(0.)\n",
      "43 tensor(0.)\n",
      "44 tensor(-0.)\n",
      "45 tensor(-0.)\n",
      "46 tensor(0.)\n",
      "47 tensor(0.)\n",
      "48 tensor(-0.)\n",
      "49 tensor(-0.)\n",
      "50 tensor(0.)\n",
      "51 tensor(-0.)\n",
      "52 tensor(0.)\n",
      "53 tensor(-0.)\n",
      "54 tensor(0.)\n",
      "55 tensor(0.)\n",
      "56 tensor(0.)\n",
      "57 tensor(0.)\n",
      "58 tensor(0.)\n",
      "59 tensor(-0.)\n",
      "60 tensor(-0.)\n",
      "61 tensor(-0.)\n",
      "62 tensor(0.)\n",
      "63 tensor(0.)\n",
      "64 tensor(-0.)\n",
      "65 tensor(0.)\n",
      "66 tensor(-0.)\n",
      "67 tensor(-0.)\n",
      "68 tensor(0.)\n",
      "69 tensor(0.)\n",
      "70 tensor(0.)\n",
      "71 tensor(-0.)\n",
      "72 tensor(-0.)\n",
      "73 tensor(0.)\n",
      "74 tensor(-0.)\n",
      "75 tensor(0.)\n",
      "76 tensor(0.)\n",
      "77 tensor(-0.)\n",
      "78 tensor(-0.)\n",
      "79 tensor(0.)\n",
      "80 tensor(-0.)\n",
      "81 tensor(0.)\n",
      "82 tensor(-0.)\n",
      "83 tensor(0.)\n",
      "84 tensor(0.)\n",
      "85 tensor(0.)\n",
      "86 tensor(0.)\n",
      "87 tensor(-0.)\n",
      "88 tensor(0.)\n",
      "89 tensor(0.)\n",
      "90 tensor(0.)\n",
      "91 tensor(0.)\n",
      "92 tensor(-0.)\n",
      "93 tensor(-0.)\n",
      "94 tensor(0.)\n",
      "95 tensor(-0.)\n",
      "96 tensor(0.)\n",
      "97 tensor(-0.)\n",
      "98 tensor(-0.)\n",
      "99 tensor(-0.)\n"
     ]
    }
   ],
   "source": [
    "check_diff(st1_iid_c, st2_iid_c, \"module.prompt.e_k_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d301f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-0.0003)\n",
      "1 tensor(0.0001)\n",
      "2 tensor(-0.0001)\n",
      "3 tensor(-0.0004)\n",
      "4 tensor(-0.0004)\n",
      "5 tensor(0.0002)\n",
      "6 tensor(-0.0006)\n",
      "7 tensor(-0.0005)\n",
      "8 tensor(-0.0003)\n",
      "9 tensor(-0.0002)\n",
      "10 tensor(-0.0038)\n",
      "11 tensor(-0.0144)\n",
      "12 tensor(-0.0157)\n",
      "13 tensor(0.0087)\n",
      "14 tensor(-0.0056)\n",
      "15 tensor(0.0053)\n",
      "16 tensor(-0.0305)\n",
      "17 tensor(0.0215)\n",
      "18 tensor(0.0056)\n",
      "19 tensor(-0.0002)\n",
      "20 tensor(0.)\n",
      "21 tensor(0.)\n",
      "22 tensor(-0.)\n",
      "23 tensor(0.)\n",
      "24 tensor(0.)\n",
      "25 tensor(0.)\n",
      "26 tensor(0.)\n",
      "27 tensor(0.)\n",
      "28 tensor(-0.)\n",
      "29 tensor(-0.)\n",
      "30 tensor(0.)\n",
      "31 tensor(0.)\n",
      "32 tensor(-0.)\n",
      "33 tensor(-0.)\n",
      "34 tensor(-0.)\n",
      "35 tensor(0.)\n",
      "36 tensor(0.)\n",
      "37 tensor(0.)\n",
      "38 tensor(-0.)\n",
      "39 tensor(-0.)\n",
      "40 tensor(-0.)\n",
      "41 tensor(0.)\n",
      "42 tensor(-0.)\n",
      "43 tensor(0.)\n",
      "44 tensor(-0.)\n",
      "45 tensor(-0.)\n",
      "46 tensor(0.)\n",
      "47 tensor(-0.)\n",
      "48 tensor(-0.)\n",
      "49 tensor(0.)\n",
      "50 tensor(-0.)\n",
      "51 tensor(-0.)\n",
      "52 tensor(0.)\n",
      "53 tensor(0.)\n",
      "54 tensor(0.)\n",
      "55 tensor(-0.)\n",
      "56 tensor(0.)\n",
      "57 tensor(-0.)\n",
      "58 tensor(0.)\n",
      "59 tensor(0.)\n",
      "60 tensor(-0.)\n",
      "61 tensor(0.)\n",
      "62 tensor(-0.)\n",
      "63 tensor(-0.)\n",
      "64 tensor(-0.)\n",
      "65 tensor(-0.)\n",
      "66 tensor(0.)\n",
      "67 tensor(0.)\n",
      "68 tensor(-0.)\n",
      "69 tensor(-0.)\n",
      "70 tensor(0.)\n",
      "71 tensor(-0.)\n",
      "72 tensor(-0.)\n",
      "73 tensor(0.)\n",
      "74 tensor(0.)\n",
      "75 tensor(-0.)\n",
      "76 tensor(0.)\n",
      "77 tensor(-0.)\n",
      "78 tensor(-0.)\n",
      "79 tensor(-0.)\n",
      "80 tensor(0.)\n",
      "81 tensor(0.)\n",
      "82 tensor(0.)\n",
      "83 tensor(-0.)\n",
      "84 tensor(0.)\n",
      "85 tensor(0.)\n",
      "86 tensor(-0.)\n",
      "87 tensor(0.)\n",
      "88 tensor(-0.)\n",
      "89 tensor(0.)\n",
      "90 tensor(-0.)\n",
      "91 tensor(0.)\n",
      "92 tensor(0.)\n",
      "93 tensor(0.)\n",
      "94 tensor(0.)\n",
      "95 tensor(-0.)\n",
      "96 tensor(-0.)\n",
      "97 tensor(-0.)\n",
      "98 tensor(0.)\n",
      "99 tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "check_diff(st1_c, st2_c, \"module.prompt.e_k_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0f39c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0025,  0.0003, -0.0010,  0.0001, -0.0009, -0.0013, -0.0010,  0.0012,\n",
      "        -0.0008,  0.0003])\n"
     ]
    }
   ],
   "source": [
    "# code to check similarity between between keys\n",
    "keys_st1_c = st1_c['module.prompt.e_k_0'][:10]\n",
    "keys_st2_c = st2_c['module.prompt.e_k_0'][10:20]\n",
    "keys_st1_iid_c = st1_iid_c['module.prompt.e_k_0']\n",
    "keys_st2_iid_c = st2_iid_c['module.prompt.e_k_0']\n",
    "\n",
    "# check cosine similarity between keys\n",
    "from torch.nn.functional import cosine_similarity\n",
    "# cosine_similarity(keys_st1_c, keys_st2_c)\n",
    "print(cosine_similarity(keys_st1_c, keys_st2_c))\n",
    "# print(cosine_similarity(keys_st1_iid_c, keys_st2_iid_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a56e3875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0009,  0.0445,  0.0502,  ..., -0.0074, -0.0005,  0.0508],\n",
       "         [-0.0407,  0.0095, -0.0284,  ...,  0.0583, -0.0792,  0.0621],\n",
       "         [-0.0107,  0.0244, -0.0327,  ..., -0.0162,  0.0312, -0.0007],\n",
       "         ...,\n",
       "         [-0.0008,  0.0014,  0.0159,  ..., -0.0132,  0.0329, -0.0555],\n",
       "         [ 0.0157,  0.0161, -0.0061,  ...,  0.0092, -0.0731,  0.0240],\n",
       "         [-0.0669, -0.0343, -0.0302,  ..., -0.0423, -0.1012, -0.0372]]),\n",
       " tensor([[ 0.0118,  0.0132,  0.0293,  ..., -0.0307, -0.0276,  0.0257],\n",
       "         [ 0.0316, -0.0251, -0.0386,  ...,  0.0276, -0.0087,  0.0170],\n",
       "         [ 0.0427,  0.0119, -0.0183,  ..., -0.0490, -0.0165,  0.0011],\n",
       "         ...,\n",
       "         [-0.0075, -0.0088, -0.0585,  ...,  0.0367, -0.0819, -0.0266],\n",
       "         [-0.0465, -0.0502, -0.0020,  ..., -0.0564,  0.0337, -0.0129],\n",
       "         [ 0.0079,  0.0078,  0.0130,  ...,  0.0435, -0.0214,  0.0448]]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_st1_c, keys_st2_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c1c781dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9632, 0.9809, 0.9350, 0.9539, 0.9575, 0.9396, 0.9395, 0.9286,\n",
      "        0.9772, 0.9320, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(keys_st1_iid_c, keys_st2_iid_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9be422c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Parameter' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# intermediate model output from the first layer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39;49mmodule\u001b[39m.\u001b[39;49mprompt\u001b[39m.\u001b[39;49me_k_0(images)\n\u001b[1;32m      3\u001b[0m output\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Parameter' object is not callable"
     ]
    }
   ],
   "source": [
    "# intermediate model output from the first layer\n",
    "output = model1.module.prompt.e_k_0(images)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "163d84e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f18013a6fb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAw/klEQVR4nO3df3TU9Z3v8dfMZGbye0J+JyQgPxREflhRaVaLKCk/dterldOrbe8pdj16dINnle22ZU+r1d09ce09rW0PxXvvurK9p2jrrujqbrWKJVxbsIKy+DMLGPkhJCCQ38kkmfneP1zTRkE+b0j4kPh8nDPnQPLmnc/3x8ybb2bmNaEgCAIBAHCGhX0vAADw6cQAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4keF7AR+VTqd14MAB5eXlKRQK+V4OAMAoCAJ1dHSosrJS4fCJr3POugF04MABVVdX+14GAOA07du3T1VVVSf8/ogNoNWrV+t73/uempubNWfOHP34xz/WpZdeetJ/l5eXJ0kqnDlO4YjbFVBudo7zuiLGq6qBvn7n2uSxPlPv1oNtzrWhPtu6gyDmXJsO2X4Tm5Pr3luSKsrL3XvnuB/LD9aS71ybl3CvlaR0kHKuLSksNPWecu5UU30q4l677ZWtpt4vv/gb59pgwJbcFY6nnWszC2wPR/197senuqzE1PtPFi8w1e/Z95/OtTmFtvtPPNLrXNvV5V4rSS3Hup1rj/a0OtcO9KfV8Pi+wcfzExmRAfTzn/9cK1eu1IMPPqh58+bpgQce0OLFi9XY2KjS0tJP/Lcf/totHAkpHHF7YAxnuD+AWgdQOu3e23W9H7L8itH+68iR6x02DqxIxP3RMyPDdkpa6qPRqKl3OnDfzljM9qCSmZlpqrcMIOt2ftKvSD4qCBsHkOFUsd5/whH3tWRkGHagpMzMuKk+Fnc/D+OZtuMTjww41w4M2O4/0Zjhvpmyv2TgZI8tI/IihO9///u6+eab9bWvfU0zZszQgw8+qOzsbP3jP/7jSPw4AMAoNOwDqK+vT9u2bVNtbe3vf0g4rNraWm3evPlj9clkUu3t7UNuAICxb9gH0Pvvv69UKqWysrIhXy8rK1Nzc/PH6uvr65VIJAZvvAABAD4dvL8PaNWqVWpraxu87du3z/eSAABnwLC/CKG4uFiRSEQtLS1Dvt7S0qLy47waKh6PKx63PeEHABj9hv0KKBaLae7cudqwYcPg19LptDZs2KCamprh/nEAgFFqRF6GvXLlSi1fvlwXX3yxLr30Uj3wwAPq6urS1772tZH4cQCAUWhEBtD111+vw4cP66677lJzc7MuvPBCPfPMMx97YQIA4NNrxJIQVqxYoRUrVpzyv08e6VMo7PYGyUzDu/4nnT/ZtI7WI0eca6sLEqbe51584oiKj8oObG9ea97/8Vccnsiuve+aehdPdE82kKTCSvftTMdsSQiN77zrXLv33aOm3hMmjHeuraqsMPXev2evqX767JnOtemUe0KAJA2k3N89H5H7myIlKW54o2NBvu254Gie+31i8nm5pt690f2m+vxK9/0Sy7O9mTc76v5MSUaO7Q3RWUXu++WckPs5nuzt14af7zlpnfdXwQEAPp0YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC9GLIrndEX68xRy/ED5A7vd43LaW5OmdVSUFTnXzr14tqn3RVUTnWuzDHEpkhSa5h6Xc6il2NS75fAhU/2+9gPOtckiW17g+8eanGuLymzb+ZkL3Y/Py5ufM/V+q3Gnqb6i+jbn2tLSbFPvmXPOca5tO+Ie8SRJl1zqHiE0bdZUU+9EsXtsU3am7f/a0cAWlxPPcl+7MVVLkZh7RNFAv+0hPSPsHsWTTrvHKnV39Uj61UnruAICAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeBEKAmPo0Qhrb29XIpFQ+bRihSNu83Gg3z3fLRWkTOspq3DPD5tYUmHqnZ1KO9dGuttMvYsLspxr89wjniRJ0dZuU31GcbVzbcVnLjH17o+GnGvjmbYNbT5w0Lm241iHqXdennvGoCSdM226c+04Y+bdkSPu26n+LlPv0uJxzrU5+fmm3iG5Z8FlZeSZemdGbIFtrrmVkhTOtOW1hbLcH6JDGbZrilDIPWcunXZfd2dHpy6eebna2tqU/wnHlSsgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXtkyIM+iLf/YZxbPc4jCCAfe+PR22KJFQyH1GZ+W6x45IUka/e9xHdjrb1jvtHsXTeuR9U+/Mc23/bympOs+5dlyRe2yPJGWn3aOVggFbhFBiasK5Ni/LvVaSIhnux0eS2rrd46YSeWWm3iXF451rIwO9pt4Zco8/CoUyTb0HQu4xTBkZtoe6WIZ7RI0kKeS+nYaHK0lSJOW+9rDc94kkpQ37UCHDPnRMD+IKCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFWZsFd8mF1crOiTnVhvvdM6RChvw1SYpl5LoXh/NNveORPOfa3IwCU++MIMe5trvHPWdMkoK4Y9DTf+npd68PpWz/J8o3ZHBlRd1rJak/7J6TFbhH0kmSIhHbedg3cNi5tr/HtphEosS5NtVry9PLirrdhyUpErY9HPWr37k2CNv2STqUttWn3c/xIGw7D0OG/RI27sNQyH3dYUMuZsRxG7kCAgB4MewD6Lvf/a5CodCQ2/Tp04f7xwAARrkR+RXcBRdcoOeff/73P8QYhQ4AGPtGZDJkZGSovLx8JFoDAMaIEXkOaOfOnaqsrNTkyZP1la98RXv37j1hbTKZVHt7+5AbAGDsG/YBNG/ePK1du1bPPPOM1qxZo6amJn3uc59TR0fHcevr6+uVSCQGb9XVtk/EBACMTsM+gJYuXaovfvGLmj17thYvXqx///d/V2trq37xi18ct37VqlVqa2sbvO3bt2+4lwQAOAuN+KsDCgoKdN5552nXrl3H/X48Hlc8bvz8dQDAqDfi7wPq7OzU7t27VVFRMdI/CgAwigz7APr617+uhoYGvfvuu/rtb3+rL3zhC4pEIvrSl7403D8KADCKDfuv4Pbv368vfelLOnLkiEpKSnT55Zdry5YtKilxj/uQpLLoecqJuUXsxDPdI3By44WmdYQC918P9qVtERsZ0SznWmvUS5B2j5HJyys29e7qsMWxbH35/znXzrnoQlPvsqqJzrWp/gFTb0sYy0DK1jsUcj8+klRmie7JcI+/kaRY3P08dA+/+UDKsBcD2fZh1LBPwmH3bZSkVGA7PpEMQ0yN8fgoPHK/qAobzkPLKZvhuOZhH0CPPvrocLcEAIxBZMEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALwY8Y9jOFVl+RcpLzfHqbbtWJdz3zff3mNax7697znXtncd/0P3TiRRUOBce975M0y9c3Pd8/HiWbbcq4HAlnn33uFW59q2zVtNvTs63dPJcjJteWA5+bnutTlu5+qHsoxryYu593/trbdMvYsNEWzVVZWm3qG0e4hhqt+WNBcKBc61kYjtoS6WYcjek5Qy/F8+ZQkZlJROu/+DtGF/S7ZMwkjEfRvTabdjwxUQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLszaKp7ctqoxUzKn26X/9N+e+u3fvNq2jr889HqQ3mTT1Tvb1Odc+v+G3pt7llRXOtRfNvdjUOys3Yapv6+p1ru3sM+TCSErLPTLlQMsRU+/2pnedaweMMTKypR8pHo8717788sum3nMvcT/+55471dQ7NeAeDZPhvomSpEja/VwJyz22R5LCEVsUjwzxOoEhQkiSArnvw0jIdk0RBO5rSaUstW51XAEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvDhrs+D+7dlnlOmYf/WrFzY49517ySWmdSxc+Hnn2vz8QlPvw4cOOdc+9H/+t6n31s3ueWAZiph6F5S558xJUizDLdNPkvIStpy5iy92P579SfdMOknqHXCv7zPk+p1KvSVTLZ2y5dJ1tR51791n24fhiOEhJmx7OArS7vuku9e27oG0LddRIff7UDSeaWodMezDtOE8+aC3+zVIKOweYBiLuZ3fXAEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvDhrs+Ae/9enFIm45StddPGlzn2/+KUbTesoLClxrg3co5IkSdHsLOfaiy76jKl387vjnGv37txl6j112vmm+itrFzrXbvj1C6bene1tzrWFBbacuZxI1LnW9Vz9PdvJkpHhflfNidt6/27Lb51r033dpt4ZmdnOtUEqMPVOpdxzz3qTtuy9rm5bFtxA2n3t+QUFpt552bnOteGwbR+azkPLA5xjLVdAAAAvzANo06ZNuvrqq1VZWalQKKQnnnhiyPeDINBdd92liooKZWVlqba2Vjt37hyu9QIAxgjzAOrq6tKcOXO0evXq437//vvv149+9CM9+OCDeumll5STk6PFixer1xiHDgAY28zPAS1dulRLly497veCINADDzygb3/727rmmmskST/96U9VVlamJ554QjfccMPprRYAMGYM63NATU1Nam5uVm1t7eDXEomE5s2bp82bNx/33ySTSbW3tw+5AQDGvmEdQM3NzZKksrKyIV8vKysb/N5H1dfXK5FIDN6qq6uHc0kAgLOU91fBrVq1Sm1tbYO3ffv2+V4SAOAMGNYBVF5eLklqaWkZ8vWWlpbB731UPB5Xfn7+kBsAYOwb1gE0adIklZeXa8OGDYNfa29v10svvaSamprh/FEAgFHO/Cq4zs5O7dr1+3fONzU1afv27SosLNSECRN0xx136G//9m917rnnatKkSfrOd76jyspKXXvttcO5bgDAKGceQFu3btWVV145+PeVK1dKkpYvX661a9fqG9/4hrq6unTLLbeotbVVl19+uZ555hllZmaafk5JWblz/MiVn1/k3DevwD2iRpIGUmnn2pT6Tb13v+v+Bt3MnLip99xLL3KuPXr4sKn3e+/YonvmfsZ9LfG4ezyRJB0zRPEUj7P9ercv6X48BzRg6h0K2eJy+kLu0TDZWe7xN5ItRqj1qPv+lqSiEvfjGTZGWYUND18FObYYptxM95gfSeofcK+PGGKVJEmBe2/3R6sPWHZ5ELh3TzvWmgfQggULFAQnzhsKhUK69957de+991pbAwA+Rby/Cg4A8OnEAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhhjuI5Uy6YNUPxuFv+WdXE8c59u3tsn7gay4g61ybT7nldkvTegb3OtQVFxiyrbPc8sKsWzjf1/l8PrDbVbz/Bp+EeT2aWLTPwcOsR59pp59g+7NAQfSXpxPFUx2XMPQvS7v0zs3JNvTPi7ufKW422HMD5xe73zXDgnkkn2bLj0iFbtpsM+XiSLdsvMJ4r6bR7JmEQsq1bIcMISLvvQ9fcOK6AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABenLVRPOPHj1dmplssi2tkjyQl+/pM60j1DzjX7tm/x9S7p6vXubawLM/UOxZ3j7RJjCs09Z578WdM9Vt/t925Nl5RaurdcaTYuTY1YItKSge2c8XEmNwTMUTDxAz3B0lqa2tzrj1yuMnU+7J5f+RcGzb+dzgdcY+/SckWxdMf2Or7AvfHibQxhili+AdhW36U0oH7iRg27G/XtlwBAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALw4a7PgioqKlJWV5VTrWidJnZ3dpnXk5uQ61+5tsmXBZceznWtbW9tNvavHVznX9qVsuVeTpk421b+85XfOtf/5xg5T74nnuG9nesA9r0uS0ul+59qubtt5NZK2bn3FVP/OrnecazNjMVPvY0cOOdeWl5SZeqvf/bzNCNsC2KLG+pghq68vbTsPUyn3emPMnEIh93UrMFyvBG4r4QoIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFWRvFkxGJKJrhtrx+Q8RKEASmdbz33nvOtdYonrw895gfSyyMJBUUFjnXBo77+UPlVRNM9YVFhc61L27fZurdfLDFuXZgwHbsWw4ddq7duXOnqffhw+69JWnXrl3OtdOnnW/qXTPvs861Tzz+L6beG3+9wbl2yqRJpt5hw/0+FjZEzkjKzskx1RcVu9/fxhW510pSOMs9/iiZsl1TpA0jIBVy7x1x3N9cAQEAvGAAAQC8MA+gTZs26eqrr1ZlZaVCoZCeeOKJId+/8cYbFQqFhtyWLFkyXOsFAIwR5gHU1dWlOXPmaPXq1SesWbJkiQ4ePDh4e+SRR05rkQCAscf8IoSlS5dq6dKln1gTj8dVXl5+yosCAIx9I/Ic0MaNG1VaWqpp06bptttu05EjR05Ym0wm1d7ePuQGABj7hn0ALVmyRD/96U+1YcMG/f3f/70aGhq0dOlSpU7wqZv19fVKJBKDt+rq6uFeEgDgLDTs7wO64YYbBv88a9YszZ49W1OmTNHGjRu1cOHCj9WvWrVKK1euHPx7e3s7QwgAPgVG/GXYkydPVnFx8QnfSBePx5Wfnz/kBgAY+0Z8AO3fv19HjhxRRUXFSP8oAMAoYv4VXGdn55CrmaamJm3fvl2FhYUqLCzUPffco2XLlqm8vFy7d+/WN77xDU2dOlWLFy8e1oUDAEY38wDaunWrrrzyysG/f/j8zfLly7VmzRrt2LFD//RP/6TW1lZVVlZq0aJF+pu/+RvF4/HhW/VHRMLuF3KxmHuukiRt2uqeTbb1d1tNvbt7upxrc/Ns2VQ9PT3OtTNmXWDqfcGUc031uYkC59pIRtTU+0Dz+861Xd3HfyHMiRw84J7X9uorr5l6W7Pg5l9xhXPtrJkzTb2ff/ZZ59pd/2nLvOs4dtS5tucy90w6SZo85Rzn2szMTFPvzqOdpvo9e3Y715YUl5h6Tz5/mnNtbmGZqXd/2v2xM23I0ws51poH0IIFCz4x0PNZw8kMAPj0IgsOAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFsH8e0HDp6O7WwCdE/vyhSIYhzyhIm9ZxrO3En+b6UZ/0ya/HXUvaPZusqqrK1LutrcO59vHHnzD1/pf+AVN9ptyOoyTlFhSZescy3TPy9hw4aOq9+SX3bL9I1JZ1+N+v/5Kpfvq57vl7j//iF6beB/btc64tKis19Q7F3B9iPnv5fFPvc6e775O+dL+pdzjlfs5KUne7+/3t0IFmU+/XXnPPGaweb/tE6crqKc61/SH3nMagL+lUxxUQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLszaKp9MQxdPe1mbo7B5/I0kzZ093rj1y6LCpd0gh59rcvFxT774+9+iRrJgtRmbHm2+Y6rOyspxrZ114oal31BD18i9P/LOpd0lxsXPt1f/tT029y4oLTfWbnnveufbdt9829S4qdY8/OvdPl5p6P9/Q4Fz75q53Tb2nTDvfuTZI2SK4XB97PpTOcL8PVU6ZaupdcOyoc+2hpiZT71Cyz7m28vyZzrUDGW77mysgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBdnbRZcVGFFA7f52HH0mHPfvPwc0zrmzLzAuba8uNTUe++evc61gWzZVEHavX7WrGmm3om8mKm+p7fXuTYatf2f6D/+Y6tzbU52nqn3V//HV5xrJ0yoMvU+dPCAqf7Vbe7b2d3Vaer9+bmLnGtzKkpMvf/xp//XuXbbK6+YetdedaVzbShsu//097tnKUpSOBJxru1JJk29C4rLnGsjafd8SUna9fabzrXZhmzEzk63c5ArIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF2dtFM+4REJZWdlOtX2GqJdQrlvPD6X63CM58vKyTL1nz5nhXHv06FFT756eHvfiIG3qveCKPzLVH2ttda7NiGWaeu/c9Y5zbX+/bTsrytyjlZK9hv0t6diR9031Tbt3OddOHD/e1HvKtPOca1t7u029q8ornGsPNTebeu/bt8+5trKq3NS71/CYIkmxmHs8laVWktp73KN7onkFpt5F490jpF7bsc25ttvx8YcrIACAF6YBVF9fr0suuUR5eXkqLS3Vtddeq8bGxiE1vb29qqurU1FRkXJzc7Vs2TK1tLQM66IBAKOfaQA1NDSorq5OW7Zs0XPPPaf+/n4tWrRIXV1dgzV33nmnnnrqKT322GNqaGjQgQMHdN111w37wgEAo5vpOaBnnnlmyN/Xrl2r0tJSbdu2TfPnz1dbW5seeughrVu3TldddZUk6eGHH9b555+vLVu26LOf/ezwrRwAMKqd1nNAbW1tkqTCwkJJ0rZt29Tf36/a2trBmunTp2vChAnavHnzcXskk0m1t7cPuQEAxr5THkDpdFp33HGHLrvsMs2cOVOS1NzcrFgspoKCgiG1ZWVlaj7BK1zq6+uVSCQGb9XV1ae6JADAKHLKA6iurk6vv/66Hn300dNawKpVq9TW1jZ4s7y0EgAwep3S+4BWrFihp59+Wps2bVJV1e9fR15eXq6+vj61trYOuQpqaWlRefnxX4cfj8cVj8dPZRkAgFHMdAUUBIFWrFih9evX64UXXtCkSZOGfH/u3LmKRqPasGHD4NcaGxu1d+9e1dTUDM+KAQBjgukKqK6uTuvWrdOTTz6pvLy8wed1EomEsrKylEgkdNNNN2nlypUqLCxUfn6+br/9dtXU1PAKOADAEKYBtGbNGknSggULhnz94Ycf1o033ihJ+sEPfqBwOKxly5YpmUxq8eLF+slPfjIsiwUAjB2mARQEwUlrMjMztXr1aq1evfqUFyVJEyaeo5ycHKfa5uYDzn0HBgZM6+hNuueHRTJsr+mIx90zoQoLx5l6RyLFzrVHjblkR1vc97ckvbdvr3Pt9BkzTb3DoZBzbVlJial3ZjzqXJsKUqbex47a9nnbMfcswLJLLjb1zspzu59JUjjbltV3/nnTnGv3vmt7AdKWLVuca2s/f5WpdyplO56WfLdw2Pjar5D7Y1CfrbMKTvDc/PEc3O+eu5hOuWVokgUHAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPDilD6O4UxIKVBKJ4/+kaRjHW3Ofbv6ukzrKC1xj7TJz8019R4YcI/YsNRKUkaGezTIeedNN/Xet2uXqT5tSDWx1ErSjOkznGtnzpxl6p3s7XGujcZtd6Vkj3tvSert6XauzUvkmXrLECGVHXU/ryRpxrTznWuT3bYgmXfeaXKuffHFF029582bZ6p3e6T6QHe3+7GUpCDlft8PGT/aJm6IVkr81ydfu8hw3EaugAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABenLVZcG/tbFRWVpZT7UB/0rnvO3sOmNbRcqjFuXba5Kmm3iUlJc61UUO2myQFafd0qrffeMvUu/Htnab6mee7Z7Bddvl8U+9QOOJcm2HMMUsN9Lv3zgiZetuqpb4+93P8/SPvm3q/s3u3c20obVt5fm6Oc200Ytwrhvy9p576V1PrPXveNdUvXrzEubZw3DhT7+xM93y3cNqWGZkyZC+OKyt1ro12uWVucgUEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPDirI3iiYfDiofd5uOx1jbnvgM9faZ17D2617m2reWIqXdWZqZzbTTmHjkjSTm5bjFGktTd1W3qPb56oql+4qTJzrX9/QOm3unA/XjGUraYkqysbOfa/qR7bI8kTZxo24d/dNUC59pINGrqXZDjHpfT1tZu6p2T5b6WC2fPMPV+ZfsrzrWhtO347G16x1Qfi7jfP8clEqbeltymyIDt2A8E7vXRHPf7QzRwiwLjCggA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxVmbBVdYUKDsbLfsoXDIPSxpXKLAtI6jR48617Yds2XBBYF7Nlm4zxAIJamrp8O5tqio2NR74oRJpvpIZty59t339pl6h8Pu+6W8tNzUOxp1X7dky5krr6gw1V+xYIFz7ZtvvGHqnWfIgsvOcs8YlKTAMRNMkioqyky9s3PdsxQrx9uOfUX5eFN9juNjlSS1t7lnV0pS1HD/yTReUwQR9xFgeZx1reUKCADghWkA1dfX65JLLlFeXp5KS0t17bXXqrGxcUjNggULFAqFhtxuvfXWYV00AGD0Mw2ghoYG1dXVacuWLXruuefU39+vRYsWqaura0jdzTffrIMHDw7e7r///mFdNABg9DM9B/TMM88M+fvatWtVWlqqbdu2af78+YNfz87OVnm57XeuAIBPl9N6Dqjtv55MKywsHPL1n/3sZyouLtbMmTO1atUqdXef+APPksmk2tvbh9wAAGPfKb8KLp1O64477tBll12mmTNnDn79y1/+siZOnKjKykrt2LFD3/zmN9XY2KjHH3/8uH3q6+t1zz33nOoyAACj1CkPoLq6Or3++ut68cUXh3z9lltuGfzzrFmzVFFRoYULF2r37t2aMmXKx/qsWrVKK1euHPx7e3u7qqurT3VZAIBR4pQG0IoVK/T0009r06ZNqqqq+sTaefPmSZJ27dp13AEUj8cVj1vebwEAGAtMAygIAt1+++1av369Nm7cqEmTTv6GxO3bt0uSKoxvvAMAjG2mAVRXV6d169bpySefVF5enpqbmyVJiURCWVlZ2r17t9atW6c//uM/VlFRkXbs2KE777xT8+fP1+zZs0dkAwAAo5NpAK1Zs0bSB282/UMPP/ywbrzxRsViMT3//PN64IEH1NXVperqai1btkzf/va3h23BAICxwfwruE9SXV2thoaG01rQh2LxuGKOzw2Nr3LPbYpmRE3rSCaTzrWHDjWbepeWljjXvv/+IVPvN9963bm2rcM9N06S9ry331SfZcgPyzQ+H1ha5p4fFonajn0qNeBcGzK+ocFyXknShAkTnGtf27HD1PvQ4cPOtUVFRabefX19zrXpdMrUOz8/z7n2iivmn7zoD3R2nPitI8djOcfTafd8PElKD7jvl85018mL/kCGIcMw3eO+Twa63GrJggMAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeHHKnwc00kpKSpSbm+tU29nZ6dzXEg0iSePGjXOuLSpyr5Wk9g7Dp7+GQ6belnX39febelsjU6KGCBzXY/6hVMp9LdZP2+2LxJxrM7NsEUIZGbbjWVBQ4FxbOb7S1PvgwYPOtZbzSrIdn97eXlPv3Fz3KJ6cnBxT786OHlN9OOz+f/l43BgJNeAeCdV7kri0jwqH3Y9Px+FjzrWf9CnYQ36+c0cAAIYRAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MVZmwUXj8cVj7vla0UiEee+lmwqSQrknq0UhGw5TLmJfOfaolTS1Lu33z3LKiNsOw2KEkWm+ljMPVMtL88930uSAkP2VWd7h6n3+8cOOdfGM923UZJyc7NM9fn57vuluqra1Pud3budazs6bPvQ9T4s2fLUJCkrK9O51hiRZs6O6zfkKcaitnMlSKWda1PGR/RY3P0fHHjnXefabsdcP66AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABenLVRPNFoVNFo1KnWEsVjjfuw6E+7x3FIUv+Ae312ti0apKpqgnNtpjEaJDviHq8iSUHaPQclM+YeryLZjn1W1LZuGVKbOjvbTa3b22znSnd3p3NtpiH+RpJyc93PrebmZlPvqqoq51pLnI0kDfQPONeGjPd7S4SQJGVkuJ+Hlvu9JEMYmBSN2h7S244cdq79j22vONcmHY8lV0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL87aLLhwOKJI2G15/X297n2j7plNkhQy1IYD2zzPCNzXUphfZOodGVfiXJsacM/UkqT+nm5TfTTD/TSzZLtJUl9fn6G37fiUV5a6F/ePM/Xu6rJlxx3raHWu7Rtwvz9I0rjCfOfalmb37DBJ6utLOtcm8m37MJrhnmEYpE2tFTE+ThjiDpVOuZ+zkhSLZTvXJo+2mnpvfOop59rxUyY71/Yk3Y47V0AAAC9MA2jNmjWaPXu28vPzlZ+fr5qaGv3yl78c/H5vb6/q6upUVFSk3NxcLVu2TC0tLcO+aADA6GcaQFVVVbrvvvu0bds2bd26VVdddZWuueYavfHGG5KkO++8U0899ZQee+wxNTQ06MCBA7ruuutGZOEAgNHN9BzQ1VdfPeTvf/d3f6c1a9Zoy5Ytqqqq0kMPPaR169bpqquukiQ9/PDDOv/887VlyxZ99rOfHb5VAwBGvVN+DiiVSunRRx9VV1eXampqtG3bNvX396u2tnawZvr06ZowYYI2b958wj7JZFLt7e1DbgCAsc88gF577TXl5uYqHo/r1ltv1fr16zVjxgw1NzcrFoupoKBgSH1ZWdknfopifX29EonE4K26utq8EQCA0cc8gKZNm6bt27frpZde0m233ably5frzTffPOUFrFq1Sm1tbYO3ffv2nXIvAMDoYX4fUCwW09SpUyVJc+fO1csvv6wf/vCHuv7669XX16fW1tYhV0EtLS0qLy8/Yb94PG7+/HUAwOh32u8DSqfTSiaTmjt3rqLRqDZs2DD4vcbGRu3du1c1NTWn+2MAAGOM6Qpo1apVWrp0qSZMmKCOjg6tW7dOGzdu1LPPPqtEIqGbbrpJK1euVGFhofLz83X77berpqaGV8ABAD7GNIAOHTqkr371qzp48KASiYRmz56tZ599Vp///OclST/4wQ8UDoe1bNkyJZNJLV68WD/5yU9OaWFhhRUOuV2ghSyBOYbIDEkKG6Jh4saolwHH7ZOkAWNcTkY46lwbNq47I8u2E0OGw5NK2TJTLMcnHRgPviG/JTvT9mvkzHihqT47P8u5tr2zw9S7y7BfolHbb+3ffvtt59p4zH0bJal6vPsLlhJ5uabeWTmZpvrMTPdYoHSQMvXev//EL+L6qLdf/Q9T70LDfqm9+k+cazs7u6T7/+dJ60xn00MPPfSJ38/MzNTq1au1evVqS1sAwKcQWXAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvzGnYIy34r1iQzs5O53/T29vrXJuRYdtkS0xNKGSLekkNuEdyWKN4olH3KJ50yhYNEqSSpvqRjOJJGdaeNibxSO5rSWe4RwJJUmCI+ZGknoEe59qurm5T7+5u9/qeHvf7mvTBB066CgLb/4d7etz3SdR4fNIh43mYdr9/WqN4LNuZ7Osz9e41HJ/Ozi732q4PaoOTxDyFgpNVnGH79+/nQ+kAYAzYt2+fqqqqTvj9s24ApdNpHThwQHl5eQr9wX+d29vbVV1drX379ik/P9/jCkcW2zl2fBq2UWI7x5rh2M4gCNTR0aHKykqFwye+sj3rfgUXDoc/cWLm5+eP6YP/IbZz7Pg0bKPEdo41p7udiUTipDW8CAEA4AUDCADgxagZQPF4XHfffbficdsHf402bOfY8WnYRontHGvO5HaedS9CAAB8OoyaKyAAwNjCAAIAeMEAAgB4wQACAHgxagbQ6tWrdc455ygzM1Pz5s3T7373O99LGlbf/e53FQqFhtymT5/ue1mnZdOmTbr66qtVWVmpUCikJ554Ysj3gyDQXXfdpYqKCmVlZam2tlY7d+70s9jTcLLtvPHGGz92bJcsWeJnsaeovr5el1xyifLy8lRaWqprr71WjY2NQ2p6e3tVV1enoqIi5ebmatmyZWppafG04lPjsp0LFiz42PG89dZbPa341KxZs0azZ88efLNpTU2NfvnLXw5+/0wdy1ExgH7+859r5cqVuvvuu/XKK69ozpw5Wrx4sQ4dOuR7acPqggsu0MGDBwdvL774ou8lnZauri7NmTNHq1evPu7377//fv3oRz/Sgw8+qJdeekk5OTlavHixKVz2bHCy7ZSkJUuWDDm2jzzyyBlc4elraGhQXV2dtmzZoueee079/f1atGiRurp+H1B555136qmnntJjjz2mhoYGHThwQNddd53HVdu5bKck3XzzzUOO5/333+9pxaemqqpK9913n7Zt26atW7fqqquu0jXXXKM33nhD0hk8lsEocOmllwZ1dXWDf0+lUkFlZWVQX1/vcVXD6+677w7mzJnjexkjRlKwfv36wb+n0+mgvLw8+N73vjf4tdbW1iAejwePPPKIhxUOj49uZxAEwfLly4NrrrnGy3pGyqFDhwJJQUNDQxAEHxy7aDQaPPbYY4M1b731ViAp2Lx5s69lnraPbmcQBMEVV1wR/MVf/IW/RY2QcePGBf/wD/9wRo/lWX8F1NfXp23btqm2tnbwa+FwWLW1tdq8ebPHlQ2/nTt3qrKyUpMnT9ZXvvIV7d271/eSRkxTU5Oam5uHHNdEIqF58+aNueMqSRs3blRpaammTZum2267TUeOHPG9pNPS1tYmSSosLJQkbdu2Tf39/UOO5/Tp0zVhwoRRfTw/up0f+tnPfqbi4mLNnDlTq1atMn2kxdkmlUrp0UcfVVdXl2pqas7osTzrwkg/6v3331cqlVJZWdmQr5eVlentt9/2tKrhN2/ePK1du1bTpk3TwYMHdc899+hzn/ucXn/9deXl5fle3rBrbm6WpOMe1w+/N1YsWbJE1113nSZNmqTdu3frr//6r7V06VJt3rxZkYjtc2rOBul0WnfccYcuu+wyzZw5U9IHxzMWi6mgoGBI7Wg+nsfbTkn68pe/rIkTJ6qyslI7duzQN7/5TTU2Nurxxx/3uFq71157TTU1Nert7VVubq7Wr1+vGTNmaPv27WfsWJ71A+jTYunSpYN/nj17tubNm6eJEyfqF7/4hW666SaPK8PpuuGGGwb/PGvWLM2ePVtTpkzRxo0btXDhQo8rOzV1dXV6/fXXR/1zlCdzou285ZZbBv88a9YsVVRUaOHChdq9e7emTJlyppd5yqZNm6bt27erra1N//zP/6zly5eroaHhjK7hrP8VXHFxsSKRyMdegdHS0qLy8nJPqxp5BQUFOu+887Rr1y7fSxkRHx67T9txlaTJkyeruLh4VB7bFStW6Omnn9avf/3rIR+bUl5err6+PrW2tg6pH63H80TbeTzz5s2TpFF3PGOxmKZOnaq5c+eqvr5ec+bM0Q9/+MMzeizP+gEUi8U0d+5cbdiwYfBr6XRaGzZsUE1NjceVjazOzk7t3r1bFRUVvpcyIiZNmqTy8vIhx7W9vV0vvfTSmD6u0gef+nvkyJFRdWyDINCKFSu0fv16vfDCC5o0adKQ78+dO1fRaHTI8WxsbNTevXtH1fE82XYez/bt2yVpVB3P40mn00omk2f2WA7rSxpGyKOPPhrE4/Fg7dq1wZtvvhnccsstQUFBQdDc3Ox7acPmL//yL4ONGzcGTU1NwW9+85ugtrY2KC4uDg4dOuR7aaeso6MjePXVV4NXX301kBR8//vfD1599dVgz549QRAEwX333RcUFBQETz75ZLBjx47gmmuuCSZNmhT09PR4XrnNJ21nR0dH8PWvfz3YvHlz0NTUFDz//PPBRRddFJx77rlBb2+v76U7u+2224JEIhFs3LgxOHjw4OCtu7t7sObWW28NJkyYELzwwgvB1q1bg5qamqCmpsbjqu1Otp27du0K7r333mDr1q1BU1NT8OSTTwaTJ08O5s+f73nlNt/61reChoaGoKmpKdixY0fwrW99KwiFQsGvfvWrIAjO3LEcFQMoCILgxz/+cTBhwoQgFosFl156abBlyxbfSxpW119/fVBRURHEYrFg/PjxwfXXXx/s2rXL97JOy69//etA0sduy5cvD4Lgg5dif+c73wnKysqCeDweLFy4MGhsbPS76FPwSdvZ3d0dLFq0KCgpKQmi0WgwceLE4Oabbx51/3k63vZJCh5++OHBmp6enuDP//zPg3HjxgXZ2dnBF77wheDgwYP+Fn0KTrade/fuDebPnx8UFhYG8Xg8mDp1avBXf/VXQVtbm9+FG/3Zn/1ZMHHixCAWiwUlJSXBwoULB4dPEJy5Y8nHMQAAvDjrnwMCAIxNDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF/8fAHKIV9r/qNMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(test_dataset.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe70af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0,\n",
       " 'aquarium_fish': 1,\n",
       " 'baby': 2,\n",
       " 'bear': 3,\n",
       " 'beaver': 4,\n",
       " 'bed': 5,\n",
       " 'bee': 6,\n",
       " 'beetle': 7,\n",
       " 'bicycle': 8,\n",
       " 'bottle': 9,\n",
       " 'bowl': 10,\n",
       " 'boy': 11,\n",
       " 'bridge': 12,\n",
       " 'bus': 13,\n",
       " 'butterfly': 14,\n",
       " 'camel': 15,\n",
       " 'can': 16,\n",
       " 'castle': 17,\n",
       " 'caterpillar': 18,\n",
       " 'cattle': 19,\n",
       " 'chair': 20,\n",
       " 'chimpanzee': 21,\n",
       " 'clock': 22,\n",
       " 'cloud': 23,\n",
       " 'cockroach': 24,\n",
       " 'couch': 25,\n",
       " 'crab': 26,\n",
       " 'crocodile': 27,\n",
       " 'cup': 28,\n",
       " 'dinosaur': 29,\n",
       " 'dolphin': 30,\n",
       " 'elephant': 31,\n",
       " 'flatfish': 32,\n",
       " 'forest': 33,\n",
       " 'fox': 34,\n",
       " 'girl': 35,\n",
       " 'hamster': 36,\n",
       " 'house': 37,\n",
       " 'kangaroo': 38,\n",
       " 'keyboard': 39,\n",
       " 'lamp': 40,\n",
       " 'lawn_mower': 41,\n",
       " 'leopard': 42,\n",
       " 'lion': 43,\n",
       " 'lizard': 44,\n",
       " 'lobster': 45,\n",
       " 'man': 46,\n",
       " 'maple_tree': 47,\n",
       " 'motorcycle': 48,\n",
       " 'mountain': 49,\n",
       " 'mouse': 50,\n",
       " 'mushroom': 51,\n",
       " 'oak_tree': 52,\n",
       " 'orange': 53,\n",
       " 'orchid': 54,\n",
       " 'otter': 55,\n",
       " 'palm_tree': 56,\n",
       " 'pear': 57,\n",
       " 'pickup_truck': 58,\n",
       " 'pine_tree': 59,\n",
       " 'plain': 60,\n",
       " 'plate': 61,\n",
       " 'poppy': 62,\n",
       " 'porcupine': 63,\n",
       " 'possum': 64,\n",
       " 'rabbit': 65,\n",
       " 'raccoon': 66,\n",
       " 'ray': 67,\n",
       " 'road': 68,\n",
       " 'rocket': 69,\n",
       " 'rose': 70,\n",
       " 'sea': 71,\n",
       " 'seal': 72,\n",
       " 'shark': 73,\n",
       " 'shrew': 74,\n",
       " 'skunk': 75,\n",
       " 'skyscraper': 76,\n",
       " 'snail': 77,\n",
       " 'snake': 78,\n",
       " 'spider': 79,\n",
       " 'squirrel': 80,\n",
       " 'streetcar': 81,\n",
       " 'sunflower': 82,\n",
       " 'sweet_pepper': 83,\n",
       " 'table': 84,\n",
       " 'tank': 85,\n",
       " 'telephone': 86,\n",
       " 'television': 87,\n",
       " 'tiger': 88,\n",
       " 'tractor': 89,\n",
       " 'train': 90,\n",
       " 'trout': 91,\n",
       " 'tulip': 92,\n",
       " 'turtle': 93,\n",
       " 'wardrobe': 94,\n",
       " 'whale': 95,\n",
       " 'willow_tree': 96,\n",
       " 'wolf': 97,\n",
       " 'woman': 98,\n",
       " 'worm': 99}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "74c96223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.last.weight\n",
      "module.last.bias\n",
      "module.prompt.e_p_0\n",
      "module.prompt.e_k_0\n",
      "module.prompt.e_a_0\n",
      "module.prompt.e_p_1\n",
      "module.prompt.e_k_1\n",
      "module.prompt.e_a_1\n",
      "module.prompt.e_p_2\n",
      "module.prompt.e_k_2\n",
      "module.prompt.e_a_2\n",
      "module.prompt.e_p_3\n",
      "module.prompt.e_k_3\n",
      "module.prompt.e_a_3\n",
      "module.prompt.e_p_4\n",
      "module.prompt.e_k_4\n",
      "module.prompt.e_a_4\n",
      "module.feat.cls_token\n",
      "module.feat.pos_embed\n",
      "module.feat.patch_embed.proj.weight\n",
      "module.feat.patch_embed.proj.bias\n",
      "module.feat.blocks.0.norm1.weight\n",
      "module.feat.blocks.0.norm1.bias\n",
      "module.feat.blocks.0.attn.qkv.weight\n",
      "module.feat.blocks.0.attn.qkv.bias\n",
      "module.feat.blocks.0.attn.proj.weight\n",
      "module.feat.blocks.0.attn.proj.bias\n",
      "module.feat.blocks.0.norm2.weight\n",
      "module.feat.blocks.0.norm2.bias\n",
      "module.feat.blocks.0.mlp.fc1.weight\n",
      "module.feat.blocks.0.mlp.fc1.bias\n",
      "module.feat.blocks.0.mlp.fc2.weight\n",
      "module.feat.blocks.0.mlp.fc2.bias\n",
      "module.feat.blocks.1.norm1.weight\n",
      "module.feat.blocks.1.norm1.bias\n",
      "module.feat.blocks.1.attn.qkv.weight\n",
      "module.feat.blocks.1.attn.qkv.bias\n",
      "module.feat.blocks.1.attn.proj.weight\n",
      "module.feat.blocks.1.attn.proj.bias\n",
      "module.feat.blocks.1.norm2.weight\n",
      "module.feat.blocks.1.norm2.bias\n",
      "module.feat.blocks.1.mlp.fc1.weight\n",
      "module.feat.blocks.1.mlp.fc1.bias\n",
      "module.feat.blocks.1.mlp.fc2.weight\n",
      "module.feat.blocks.1.mlp.fc2.bias\n",
      "module.feat.blocks.2.norm1.weight\n",
      "module.feat.blocks.2.norm1.bias\n",
      "module.feat.blocks.2.attn.qkv.weight\n",
      "module.feat.blocks.2.attn.qkv.bias\n",
      "module.feat.blocks.2.attn.proj.weight\n",
      "module.feat.blocks.2.attn.proj.bias\n",
      "module.feat.blocks.2.norm2.weight\n",
      "module.feat.blocks.2.norm2.bias\n",
      "module.feat.blocks.2.mlp.fc1.weight\n",
      "module.feat.blocks.2.mlp.fc1.bias\n",
      "module.feat.blocks.2.mlp.fc2.weight\n",
      "module.feat.blocks.2.mlp.fc2.bias\n",
      "module.feat.blocks.3.norm1.weight\n",
      "module.feat.blocks.3.norm1.bias\n",
      "module.feat.blocks.3.attn.qkv.weight\n",
      "module.feat.blocks.3.attn.qkv.bias\n",
      "module.feat.blocks.3.attn.proj.weight\n",
      "module.feat.blocks.3.attn.proj.bias\n",
      "module.feat.blocks.3.norm2.weight\n",
      "module.feat.blocks.3.norm2.bias\n",
      "module.feat.blocks.3.mlp.fc1.weight\n",
      "module.feat.blocks.3.mlp.fc1.bias\n",
      "module.feat.blocks.3.mlp.fc2.weight\n",
      "module.feat.blocks.3.mlp.fc2.bias\n",
      "module.feat.blocks.4.norm1.weight\n",
      "module.feat.blocks.4.norm1.bias\n",
      "module.feat.blocks.4.attn.qkv.weight\n",
      "module.feat.blocks.4.attn.qkv.bias\n",
      "module.feat.blocks.4.attn.proj.weight\n",
      "module.feat.blocks.4.attn.proj.bias\n",
      "module.feat.blocks.4.norm2.weight\n",
      "module.feat.blocks.4.norm2.bias\n",
      "module.feat.blocks.4.mlp.fc1.weight\n",
      "module.feat.blocks.4.mlp.fc1.bias\n",
      "module.feat.blocks.4.mlp.fc2.weight\n",
      "module.feat.blocks.4.mlp.fc2.bias\n",
      "module.feat.blocks.5.norm1.weight\n",
      "module.feat.blocks.5.norm1.bias\n",
      "module.feat.blocks.5.attn.qkv.weight\n",
      "module.feat.blocks.5.attn.qkv.bias\n",
      "module.feat.blocks.5.attn.proj.weight\n",
      "module.feat.blocks.5.attn.proj.bias\n",
      "module.feat.blocks.5.norm2.weight\n",
      "module.feat.blocks.5.norm2.bias\n",
      "module.feat.blocks.5.mlp.fc1.weight\n",
      "module.feat.blocks.5.mlp.fc1.bias\n",
      "module.feat.blocks.5.mlp.fc2.weight\n",
      "module.feat.blocks.5.mlp.fc2.bias\n",
      "module.feat.blocks.6.norm1.weight\n",
      "module.feat.blocks.6.norm1.bias\n",
      "module.feat.blocks.6.attn.qkv.weight\n",
      "module.feat.blocks.6.attn.qkv.bias\n",
      "module.feat.blocks.6.attn.proj.weight\n",
      "module.feat.blocks.6.attn.proj.bias\n",
      "module.feat.blocks.6.norm2.weight\n",
      "module.feat.blocks.6.norm2.bias\n",
      "module.feat.blocks.6.mlp.fc1.weight\n",
      "module.feat.blocks.6.mlp.fc1.bias\n",
      "module.feat.blocks.6.mlp.fc2.weight\n",
      "module.feat.blocks.6.mlp.fc2.bias\n",
      "module.feat.blocks.7.norm1.weight\n",
      "module.feat.blocks.7.norm1.bias\n",
      "module.feat.blocks.7.attn.qkv.weight\n",
      "module.feat.blocks.7.attn.qkv.bias\n",
      "module.feat.blocks.7.attn.proj.weight\n",
      "module.feat.blocks.7.attn.proj.bias\n",
      "module.feat.blocks.7.norm2.weight\n",
      "module.feat.blocks.7.norm2.bias\n",
      "module.feat.blocks.7.mlp.fc1.weight\n",
      "module.feat.blocks.7.mlp.fc1.bias\n",
      "module.feat.blocks.7.mlp.fc2.weight\n",
      "module.feat.blocks.7.mlp.fc2.bias\n",
      "module.feat.blocks.8.norm1.weight\n",
      "module.feat.blocks.8.norm1.bias\n",
      "module.feat.blocks.8.attn.qkv.weight\n",
      "module.feat.blocks.8.attn.qkv.bias\n",
      "module.feat.blocks.8.attn.proj.weight\n",
      "module.feat.blocks.8.attn.proj.bias\n",
      "module.feat.blocks.8.norm2.weight\n",
      "module.feat.blocks.8.norm2.bias\n",
      "module.feat.blocks.8.mlp.fc1.weight\n",
      "module.feat.blocks.8.mlp.fc1.bias\n",
      "module.feat.blocks.8.mlp.fc2.weight\n",
      "module.feat.blocks.8.mlp.fc2.bias\n",
      "module.feat.blocks.9.norm1.weight\n",
      "module.feat.blocks.9.norm1.bias\n",
      "module.feat.blocks.9.attn.qkv.weight\n",
      "module.feat.blocks.9.attn.qkv.bias\n",
      "module.feat.blocks.9.attn.proj.weight\n",
      "module.feat.blocks.9.attn.proj.bias\n",
      "module.feat.blocks.9.norm2.weight\n",
      "module.feat.blocks.9.norm2.bias\n",
      "module.feat.blocks.9.mlp.fc1.weight\n",
      "module.feat.blocks.9.mlp.fc1.bias\n",
      "module.feat.blocks.9.mlp.fc2.weight\n",
      "module.feat.blocks.9.mlp.fc2.bias\n",
      "module.feat.blocks.10.norm1.weight\n",
      "module.feat.blocks.10.norm1.bias\n",
      "module.feat.blocks.10.attn.qkv.weight\n",
      "module.feat.blocks.10.attn.qkv.bias\n",
      "module.feat.blocks.10.attn.proj.weight\n",
      "module.feat.blocks.10.attn.proj.bias\n",
      "module.feat.blocks.10.norm2.weight\n",
      "module.feat.blocks.10.norm2.bias\n",
      "module.feat.blocks.10.mlp.fc1.weight\n",
      "module.feat.blocks.10.mlp.fc1.bias\n",
      "module.feat.blocks.10.mlp.fc2.weight\n",
      "module.feat.blocks.10.mlp.fc2.bias\n",
      "module.feat.blocks.11.norm1.weight\n",
      "module.feat.blocks.11.norm1.bias\n",
      "module.feat.blocks.11.attn.qkv.weight\n",
      "module.feat.blocks.11.attn.qkv.bias\n",
      "module.feat.blocks.11.attn.proj.weight\n",
      "module.feat.blocks.11.attn.proj.bias\n",
      "module.feat.blocks.11.norm2.weight\n",
      "module.feat.blocks.11.norm2.bias\n",
      "module.feat.blocks.11.mlp.fc1.weight\n",
      "module.feat.blocks.11.mlp.fc1.bias\n",
      "module.feat.blocks.11.mlp.fc2.weight\n",
      "module.feat.blocks.11.mlp.fc2.bias\n",
      "module.feat.norm.weight\n",
      "module.feat.norm.bias\n"
     ]
    }
   ],
   "source": [
    "for key in st1.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7911ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptFCL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "706466e2cd6ba47dc72a23aff5b4b412fa3e343d00dce46686a6ac93eab9d9be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
