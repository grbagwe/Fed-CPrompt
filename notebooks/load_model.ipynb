{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d80eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# module_path = os.path.abspath(os.path.join('../../Prompt-based-class-incremental-learning-in-Federated-Learning/CODA_Prompt_CVPR2023_Code/'))\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import torch, torchvision, numpy as np\n",
    "from dataloaders import dataloader\n",
    "from dataloaders.dataloader import iCIFAR100_Fed\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4784cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841fd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import vision_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4ae507",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vision_transformer.VisionTransformer(img_size=224, patch_size=16, embed_dim=768, depth=12,\n",
    "                                           num_heads=12, use_grad_checkpointing=False, ckpt_layer=0,\n",
    "                                           drop_path_rate=0\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28fe5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "load_dict = timm.models.vit_base_patch16_224(pretrained=True).state_dict()\n",
    "del load_dict[\"head.weight\"]\n",
    "del load_dict[\"head.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9d950e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(load_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b99d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=100, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(768, 100)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237c27a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.0278, -0.0086,  0.0053,  ...,  0.0023, -0.0287, -0.0135],\n",
       "                      [-0.0336, -0.0264,  0.0333,  ..., -0.0191,  0.0237, -0.0341],\n",
       "                      [-0.0200, -0.0321, -0.0032,  ..., -0.0112, -0.0101, -0.0245],\n",
       "                      ...,\n",
       "                      [ 0.0112, -0.0077, -0.0156,  ...,  0.0037, -0.0022,  0.0004],\n",
       "                      [ 0.0169,  0.0045, -0.0015,  ..., -0.0142, -0.0232, -0.0052],\n",
       "                      [ 0.0154,  0.0060,  0.0152,  ...,  0.0307,  0.0008, -0.0304]])),\n",
       "             ('bias',\n",
       "              tensor([-0.0209,  0.0268,  0.0262, -0.0185, -0.0050,  0.0313, -0.0027, -0.0018,\n",
       "                       0.0208, -0.0149,  0.0075,  0.0248, -0.0015,  0.0060, -0.0060,  0.0201,\n",
       "                      -0.0202,  0.0045,  0.0237,  0.0330,  0.0091, -0.0041,  0.0115, -0.0254,\n",
       "                      -0.0019,  0.0238, -0.0083, -0.0210,  0.0220, -0.0094, -0.0227,  0.0088,\n",
       "                      -0.0287,  0.0092, -0.0261, -0.0031,  0.0134, -0.0338, -0.0251, -0.0212,\n",
       "                      -0.0097,  0.0024,  0.0012, -0.0001, -0.0023, -0.0190,  0.0260,  0.0045,\n",
       "                       0.0356, -0.0025,  0.0327,  0.0226,  0.0348,  0.0239, -0.0048,  0.0244,\n",
       "                      -0.0358,  0.0241,  0.0059,  0.0014, -0.0174,  0.0229,  0.0192, -0.0142,\n",
       "                      -0.0231,  0.0150, -0.0103,  0.0007,  0.0351, -0.0053, -0.0351, -0.0340,\n",
       "                      -0.0046, -0.0069,  0.0224, -0.0333,  0.0211,  0.0077,  0.0304,  0.0174,\n",
       "                       0.0095,  0.0311,  0.0022, -0.0063,  0.0184, -0.0124,  0.0140, -0.0066,\n",
       "                       0.0166,  0.0086,  0.0100, -0.0120,  0.0041, -0.0155, -0.0129, -0.0196,\n",
       "                       0.0219, -0.0133, -0.0097,  0.0006]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f057e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch AMP is not available on this platform\n"
     ]
    }
   ],
   "source": [
    "# !pip install fairscale\n",
    "from models.vit_coda_p import vit_pt_imnet\n",
    "import models\n",
    "from models import  vit_coda_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ef91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_params = [10, [100, 8, 0 ,0 ,0]]\n",
    "\n",
    "dual_prompt_params  = [10, [10, 20, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773e92ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++ in feature+++++++++++++++++++++\n",
      " freezing original model\n",
      "freezing cls_token\n",
      "freezing pos_embed\n",
      "freezing patch_embed.proj.weight\n",
      "freezing patch_embed.proj.bias\n",
      "freezing blocks.0.norm1.weight\n",
      "freezing blocks.0.norm1.bias\n",
      "freezing blocks.0.attn.qkv.weight\n",
      "freezing blocks.0.attn.qkv.bias\n",
      "freezing blocks.0.attn.proj.weight\n",
      "freezing blocks.0.attn.proj.bias\n",
      "freezing blocks.0.norm2.weight\n",
      "freezing blocks.0.norm2.bias\n",
      "freezing blocks.0.mlp.fc1.weight\n",
      "freezing blocks.0.mlp.fc1.bias\n",
      "freezing blocks.0.mlp.fc2.weight\n",
      "freezing blocks.0.mlp.fc2.bias\n",
      "freezing blocks.1.norm1.weight\n",
      "freezing blocks.1.norm1.bias\n",
      "freezing blocks.1.attn.qkv.weight\n",
      "freezing blocks.1.attn.qkv.bias\n",
      "freezing blocks.1.attn.proj.weight\n",
      "freezing blocks.1.attn.proj.bias\n",
      "freezing blocks.1.norm2.weight\n",
      "freezing blocks.1.norm2.bias\n",
      "freezing blocks.1.mlp.fc1.weight\n",
      "freezing blocks.1.mlp.fc1.bias\n",
      "freezing blocks.1.mlp.fc2.weight\n",
      "freezing blocks.1.mlp.fc2.bias\n",
      "freezing blocks.2.norm1.weight\n",
      "freezing blocks.2.norm1.bias\n",
      "freezing blocks.2.attn.qkv.weight\n",
      "freezing blocks.2.attn.qkv.bias\n",
      "freezing blocks.2.attn.proj.weight\n",
      "freezing blocks.2.attn.proj.bias\n",
      "freezing blocks.2.norm2.weight\n",
      "freezing blocks.2.norm2.bias\n",
      "freezing blocks.2.mlp.fc1.weight\n",
      "freezing blocks.2.mlp.fc1.bias\n",
      "freezing blocks.2.mlp.fc2.weight\n",
      "freezing blocks.2.mlp.fc2.bias\n",
      "freezing blocks.3.norm1.weight\n",
      "freezing blocks.3.norm1.bias\n",
      "freezing blocks.3.attn.qkv.weight\n",
      "freezing blocks.3.attn.qkv.bias\n",
      "freezing blocks.3.attn.proj.weight\n",
      "freezing blocks.3.attn.proj.bias\n",
      "freezing blocks.3.norm2.weight\n",
      "freezing blocks.3.norm2.bias\n",
      "freezing blocks.3.mlp.fc1.weight\n",
      "freezing blocks.3.mlp.fc1.bias\n",
      "freezing blocks.3.mlp.fc2.weight\n",
      "freezing blocks.3.mlp.fc2.bias\n",
      "freezing blocks.4.norm1.weight\n",
      "freezing blocks.4.norm1.bias\n",
      "freezing blocks.4.attn.qkv.weight\n",
      "freezing blocks.4.attn.qkv.bias\n",
      "freezing blocks.4.attn.proj.weight\n",
      "freezing blocks.4.attn.proj.bias\n",
      "freezing blocks.4.norm2.weight\n",
      "freezing blocks.4.norm2.bias\n",
      "freezing blocks.4.mlp.fc1.weight\n",
      "freezing blocks.4.mlp.fc1.bias\n",
      "freezing blocks.4.mlp.fc2.weight\n",
      "freezing blocks.4.mlp.fc2.bias\n",
      "freezing blocks.5.norm1.weight\n",
      "freezing blocks.5.norm1.bias\n",
      "freezing blocks.5.attn.qkv.weight\n",
      "freezing blocks.5.attn.qkv.bias\n",
      "freezing blocks.5.attn.proj.weight\n",
      "freezing blocks.5.attn.proj.bias\n",
      "freezing blocks.5.norm2.weight\n",
      "freezing blocks.5.norm2.bias\n",
      "freezing blocks.5.mlp.fc1.weight\n",
      "freezing blocks.5.mlp.fc1.bias\n",
      "freezing blocks.5.mlp.fc2.weight\n",
      "freezing blocks.5.mlp.fc2.bias\n",
      "freezing blocks.6.norm1.weight\n",
      "freezing blocks.6.norm1.bias\n",
      "freezing blocks.6.attn.qkv.weight\n",
      "freezing blocks.6.attn.qkv.bias\n",
      "freezing blocks.6.attn.proj.weight\n",
      "freezing blocks.6.attn.proj.bias\n",
      "freezing blocks.6.norm2.weight\n",
      "freezing blocks.6.norm2.bias\n",
      "freezing blocks.6.mlp.fc1.weight\n",
      "freezing blocks.6.mlp.fc1.bias\n",
      "freezing blocks.6.mlp.fc2.weight\n",
      "freezing blocks.6.mlp.fc2.bias\n",
      "freezing blocks.7.norm1.weight\n",
      "freezing blocks.7.norm1.bias\n",
      "freezing blocks.7.attn.qkv.weight\n",
      "freezing blocks.7.attn.qkv.bias\n",
      "freezing blocks.7.attn.proj.weight\n",
      "freezing blocks.7.attn.proj.bias\n",
      "freezing blocks.7.norm2.weight\n",
      "freezing blocks.7.norm2.bias\n",
      "freezing blocks.7.mlp.fc1.weight\n",
      "freezing blocks.7.mlp.fc1.bias\n",
      "freezing blocks.7.mlp.fc2.weight\n",
      "freezing blocks.7.mlp.fc2.bias\n",
      "freezing blocks.8.norm1.weight\n",
      "freezing blocks.8.norm1.bias\n",
      "freezing blocks.8.attn.qkv.weight\n",
      "freezing blocks.8.attn.qkv.bias\n",
      "freezing blocks.8.attn.proj.weight\n",
      "freezing blocks.8.attn.proj.bias\n",
      "freezing blocks.8.norm2.weight\n",
      "freezing blocks.8.norm2.bias\n",
      "freezing blocks.8.mlp.fc1.weight\n",
      "freezing blocks.8.mlp.fc1.bias\n",
      "freezing blocks.8.mlp.fc2.weight\n",
      "freezing blocks.8.mlp.fc2.bias\n",
      "freezing blocks.9.norm1.weight\n",
      "freezing blocks.9.norm1.bias\n",
      "freezing blocks.9.attn.qkv.weight\n",
      "freezing blocks.9.attn.qkv.bias\n",
      "freezing blocks.9.attn.proj.weight\n",
      "freezing blocks.9.attn.proj.bias\n",
      "freezing blocks.9.norm2.weight\n",
      "freezing blocks.9.norm2.bias\n",
      "freezing blocks.9.mlp.fc1.weight\n",
      "freezing blocks.9.mlp.fc1.bias\n",
      "freezing blocks.9.mlp.fc2.weight\n",
      "freezing blocks.9.mlp.fc2.bias\n",
      "freezing blocks.10.norm1.weight\n",
      "freezing blocks.10.norm1.bias\n",
      "freezing blocks.10.attn.qkv.weight\n",
      "freezing blocks.10.attn.qkv.bias\n",
      "freezing blocks.10.attn.proj.weight\n",
      "freezing blocks.10.attn.proj.bias\n",
      "freezing blocks.10.norm2.weight\n",
      "freezing blocks.10.norm2.bias\n",
      "freezing blocks.10.mlp.fc1.weight\n",
      "freezing blocks.10.mlp.fc1.bias\n",
      "freezing blocks.10.mlp.fc2.weight\n",
      "freezing blocks.10.mlp.fc2.bias\n",
      "freezing blocks.11.norm1.weight\n",
      "freezing blocks.11.norm1.bias\n",
      "freezing blocks.11.attn.qkv.weight\n",
      "freezing blocks.11.attn.qkv.bias\n",
      "freezing blocks.11.attn.proj.weight\n",
      "freezing blocks.11.attn.proj.bias\n",
      "freezing blocks.11.norm2.weight\n",
      "freezing blocks.11.norm2.bias\n",
      "freezing blocks.11.mlp.fc1.weight\n",
      "freezing blocks.11.mlp.fc1.bias\n",
      "freezing blocks.11.mlp.fc2.weight\n",
      "freezing blocks.11.mlp.fc2.bias\n",
      "freezing norm.weight\n",
      "freezing norm.bias\n",
      " in CODA prompt\n",
      "ortho_mu  0\n"
     ]
    }
   ],
   "source": [
    "model_codap = vit_pt_imnet(out_dim=100, prompt_flag = 'codap', prompt_param=prompt_params)\n",
    "# model_dual = vit_pt_imnet(out_dim=100, prompt_flag = 'dual', prompt_param=dual_prompt_params)\n",
    "# model_l2p = vit_coda_p.vit_pt_imnet(out_dim=100, prompt_flag = 'l2p', prompt_param=prompt_params)\n",
    "# model_base = vit_pt_imnet(out_dim=100, prompt_flag = \"None\", prompt_param=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d49541cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.module.prompt.e_p_0 Parameter containing:\n",
      "tensor([[[ 2.3563e-02, -1.0315e-02, -1.0168e-02,  ..., -1.5726e-02,\n",
      "          -2.1585e-02,  2.3653e-03],\n",
      "         [-1.1744e-02, -1.0223e-02,  1.0154e-02,  ...,  8.8750e-03,\n",
      "           1.4252e-02, -1.2140e-02],\n",
      "         [ 3.5424e-03,  3.0761e-03,  6.4863e-03,  ...,  2.7715e-02,\n",
      "           1.1071e-02, -7.9777e-03],\n",
      "         ...,\n",
      "         [ 1.2643e-02,  8.7863e-03,  1.7152e-02,  ...,  1.4557e-04,\n",
      "           2.4014e-03, -2.2078e-03],\n",
      "         [-2.2192e-02,  5.5119e-03,  6.7970e-03,  ...,  2.7172e-03,\n",
      "           1.5036e-02,  4.2390e-03],\n",
      "         [ 1.4510e-03, -8.8770e-03,  1.6154e-02,  ..., -2.0709e-02,\n",
      "           1.1269e-02, -1.6108e-02]],\n",
      "\n",
      "        [[-1.1156e-02, -7.2050e-04, -2.8015e-03,  ...,  2.0302e-02,\n",
      "          -7.6398e-03, -2.2658e-02],\n",
      "         [ 1.1487e-02, -7.3623e-04,  1.7722e-02,  ...,  9.5978e-03,\n",
      "           2.4161e-02, -6.7583e-03],\n",
      "         [ 1.8390e-02, -5.6575e-03,  1.1179e-02,  ...,  1.2168e-02,\n",
      "           2.4071e-03,  1.1656e-02],\n",
      "         ...,\n",
      "         [-2.1148e-02,  1.5401e-02, -1.3265e-02,  ...,  7.1572e-03,\n",
      "          -7.6303e-03,  1.5587e-02],\n",
      "         [ 2.2880e-03,  1.4268e-02,  1.2587e-02,  ...,  1.5405e-02,\n",
      "           8.8274e-03,  1.5082e-02],\n",
      "         [ 7.8978e-03,  2.0197e-02,  2.5714e-02,  ..., -4.7982e-03,\n",
      "           3.5334e-03,  1.9616e-02]],\n",
      "\n",
      "        [[ 1.3260e-02, -1.9716e-03,  6.9630e-04,  ...,  5.8679e-03,\n",
      "           8.6892e-03,  1.8068e-02],\n",
      "         [ 2.0802e-03, -1.6707e-02,  1.1854e-03,  ...,  1.6260e-02,\n",
      "          -1.3329e-02, -1.6328e-03],\n",
      "         [ 1.6024e-02,  1.7649e-02,  1.0832e-02,  ...,  3.1194e-03,\n",
      "          -6.7639e-05,  2.5182e-02],\n",
      "         ...,\n",
      "         [-3.4891e-04, -6.5900e-03,  5.0852e-03,  ..., -1.0990e-02,\n",
      "          -2.0785e-03, -6.6391e-03],\n",
      "         [-2.0948e-03, -6.0902e-03, -6.7628e-03,  ...,  3.6928e-04,\n",
      "          -1.0974e-02,  6.9652e-03],\n",
      "         [-2.3692e-02,  1.1725e-03, -2.6423e-02,  ..., -7.9391e-03,\n",
      "          -1.3314e-03, -1.6088e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2640e-02,  1.6270e-02, -1.8481e-02,  ...,  1.3973e-02,\n",
      "           1.2339e-03, -4.7861e-03],\n",
      "         [ 3.0574e-03, -2.3851e-02,  2.4293e-03,  ..., -1.6150e-02,\n",
      "          -2.0544e-02,  7.4125e-03],\n",
      "         [-1.3228e-02,  4.7478e-03, -9.3148e-03,  ..., -3.4145e-03,\n",
      "           2.3370e-02,  5.6297e-03],\n",
      "         ...,\n",
      "         [ 1.4969e-02,  1.8796e-02, -4.2763e-04,  ...,  8.4778e-04,\n",
      "           2.9382e-02, -1.3249e-02],\n",
      "         [-6.9067e-03,  2.2692e-03, -5.9566e-03,  ..., -1.9759e-02,\n",
      "           1.8213e-02,  1.0382e-02],\n",
      "         [ 2.4004e-02, -6.8117e-03, -2.7038e-02,  ...,  9.8265e-03,\n",
      "           1.4823e-02, -1.1625e-03]],\n",
      "\n",
      "        [[-2.5738e-02, -5.7477e-03,  8.9914e-03,  ...,  2.2954e-02,\n",
      "          -3.5419e-03,  1.3523e-02],\n",
      "         [ 1.3693e-02, -1.1291e-02, -1.2979e-02,  ...,  1.2929e-02,\n",
      "          -1.6659e-02, -1.1626e-02],\n",
      "         [ 8.5505e-03, -3.7143e-03,  3.8994e-03,  ..., -1.7489e-02,\n",
      "          -2.2519e-03,  1.1167e-02],\n",
      "         ...,\n",
      "         [ 1.0913e-02, -9.9102e-04,  1.3722e-02,  ..., -1.4744e-02,\n",
      "          -1.5244e-02, -8.3903e-03],\n",
      "         [-8.7899e-03,  3.5177e-03,  7.1983e-03,  ...,  8.5022e-03,\n",
      "           7.0314e-03,  1.5907e-02],\n",
      "         [ 3.3316e-03,  2.0837e-02,  6.4376e-03,  ..., -2.9049e-03,\n",
      "           1.8370e-03, -7.6731e-03]],\n",
      "\n",
      "        [[-8.8159e-03,  5.6343e-03,  2.5338e-03,  ..., -2.7603e-02,\n",
      "           4.0982e-03, -3.7159e-03],\n",
      "         [-4.3175e-03,  1.0609e-02, -3.5750e-03,  ..., -2.7946e-02,\n",
      "           3.3479e-02,  3.7942e-03],\n",
      "         [-2.6359e-03,  5.7402e-03,  2.6835e-03,  ...,  1.8342e-02,\n",
      "          -7.6211e-03, -6.6118e-03],\n",
      "         ...,\n",
      "         [ 1.3253e-02,  2.3079e-02,  1.2156e-02,  ...,  1.0958e-03,\n",
      "          -2.8559e-02,  8.0496e-03],\n",
      "         [ 4.4884e-03, -9.4963e-04, -1.3429e-02,  ...,  1.3541e-03,\n",
      "          -1.0659e-02,  1.0495e-02],\n",
      "         [-3.6830e-04,  1.8373e-02,  3.6954e-02,  ..., -6.9785e-03,\n",
      "          -3.6250e-03,  1.0138e-02]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model_codap = torch.nn.DataParallel(model_codap)\n",
    "model_codap.cuda()\n",
    "for key, param in model_codap.named_parameters():\n",
    "    if 'module.prompt.e_p_0' in key: \n",
    "        print(key, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29fe8c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.3563e-02, -1.0315e-02, -1.0168e-02,  ..., -1.5726e-02,\n",
       "          -2.1585e-02,  2.3653e-03],\n",
       "         [-1.1744e-02, -1.0223e-02,  1.0154e-02,  ...,  8.8750e-03,\n",
       "           1.4252e-02, -1.2140e-02],\n",
       "         [ 3.5424e-03,  3.0761e-03,  6.4863e-03,  ...,  2.7715e-02,\n",
       "           1.1071e-02, -7.9777e-03],\n",
       "         ...,\n",
       "         [ 1.2643e-02,  8.7863e-03,  1.7152e-02,  ...,  1.4557e-04,\n",
       "           2.4014e-03, -2.2078e-03],\n",
       "         [-2.2192e-02,  5.5119e-03,  6.7970e-03,  ...,  2.7172e-03,\n",
       "           1.5036e-02,  4.2390e-03],\n",
       "         [ 1.4510e-03, -8.8770e-03,  1.6154e-02,  ..., -2.0709e-02,\n",
       "           1.1269e-02, -1.6108e-02]],\n",
       "\n",
       "        [[-1.1156e-02, -7.2050e-04, -2.8015e-03,  ...,  2.0302e-02,\n",
       "          -7.6398e-03, -2.2658e-02],\n",
       "         [ 1.1487e-02, -7.3623e-04,  1.7722e-02,  ...,  9.5978e-03,\n",
       "           2.4161e-02, -6.7583e-03],\n",
       "         [ 1.8390e-02, -5.6575e-03,  1.1179e-02,  ...,  1.2168e-02,\n",
       "           2.4071e-03,  1.1656e-02],\n",
       "         ...,\n",
       "         [-2.1148e-02,  1.5401e-02, -1.3265e-02,  ...,  7.1572e-03,\n",
       "          -7.6303e-03,  1.5587e-02],\n",
       "         [ 2.2880e-03,  1.4268e-02,  1.2587e-02,  ...,  1.5405e-02,\n",
       "           8.8274e-03,  1.5082e-02],\n",
       "         [ 7.8978e-03,  2.0197e-02,  2.5714e-02,  ..., -4.7982e-03,\n",
       "           3.5334e-03,  1.9616e-02]],\n",
       "\n",
       "        [[ 1.3260e-02, -1.9716e-03,  6.9630e-04,  ...,  5.8679e-03,\n",
       "           8.6892e-03,  1.8068e-02],\n",
       "         [ 2.0802e-03, -1.6707e-02,  1.1854e-03,  ...,  1.6260e-02,\n",
       "          -1.3329e-02, -1.6328e-03],\n",
       "         [ 1.6024e-02,  1.7649e-02,  1.0832e-02,  ...,  3.1194e-03,\n",
       "          -6.7639e-05,  2.5182e-02],\n",
       "         ...,\n",
       "         [-3.4891e-04, -6.5900e-03,  5.0852e-03,  ..., -1.0990e-02,\n",
       "          -2.0785e-03, -6.6391e-03],\n",
       "         [-2.0948e-03, -6.0902e-03, -6.7628e-03,  ...,  3.6928e-04,\n",
       "          -1.0974e-02,  6.9652e-03],\n",
       "         [-2.3692e-02,  1.1725e-03, -2.6423e-02,  ..., -7.9391e-03,\n",
       "          -1.3314e-03, -1.6088e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2640e-02,  1.6270e-02, -1.8481e-02,  ...,  1.3973e-02,\n",
       "           1.2339e-03, -4.7861e-03],\n",
       "         [ 3.0574e-03, -2.3851e-02,  2.4293e-03,  ..., -1.6150e-02,\n",
       "          -2.0544e-02,  7.4125e-03],\n",
       "         [-1.3228e-02,  4.7478e-03, -9.3148e-03,  ..., -3.4145e-03,\n",
       "           2.3370e-02,  5.6297e-03],\n",
       "         ...,\n",
       "         [ 1.4969e-02,  1.8796e-02, -4.2763e-04,  ...,  8.4778e-04,\n",
       "           2.9382e-02, -1.3249e-02],\n",
       "         [-6.9067e-03,  2.2692e-03, -5.9566e-03,  ..., -1.9759e-02,\n",
       "           1.8213e-02,  1.0382e-02],\n",
       "         [ 2.4004e-02, -6.8117e-03, -2.7038e-02,  ...,  9.8265e-03,\n",
       "           1.4823e-02, -1.1625e-03]],\n",
       "\n",
       "        [[-2.5738e-02, -5.7477e-03,  8.9914e-03,  ...,  2.2954e-02,\n",
       "          -3.5419e-03,  1.3523e-02],\n",
       "         [ 1.3693e-02, -1.1291e-02, -1.2979e-02,  ...,  1.2929e-02,\n",
       "          -1.6659e-02, -1.1626e-02],\n",
       "         [ 8.5505e-03, -3.7143e-03,  3.8994e-03,  ..., -1.7489e-02,\n",
       "          -2.2519e-03,  1.1167e-02],\n",
       "         ...,\n",
       "         [ 1.0913e-02, -9.9102e-04,  1.3722e-02,  ..., -1.4744e-02,\n",
       "          -1.5244e-02, -8.3903e-03],\n",
       "         [-8.7899e-03,  3.5177e-03,  7.1983e-03,  ...,  8.5022e-03,\n",
       "           7.0314e-03,  1.5907e-02],\n",
       "         [ 3.3316e-03,  2.0837e-02,  6.4376e-03,  ..., -2.9049e-03,\n",
       "           1.8370e-03, -7.6731e-03]],\n",
       "\n",
       "        [[-8.8159e-03,  5.6343e-03,  2.5338e-03,  ..., -2.7603e-02,\n",
       "           4.0982e-03, -3.7159e-03],\n",
       "         [-4.3175e-03,  1.0609e-02, -3.5750e-03,  ..., -2.7946e-02,\n",
       "           3.3479e-02,  3.7942e-03],\n",
       "         [-2.6359e-03,  5.7402e-03,  2.6835e-03,  ...,  1.8342e-02,\n",
       "          -7.6211e-03, -6.6118e-03],\n",
       "         ...,\n",
       "         [ 1.3253e-02,  2.3079e-02,  1.2156e-02,  ...,  1.0958e-03,\n",
       "          -2.8559e-02,  8.0496e-03],\n",
       "         [ 4.4884e-03, -9.4963e-04, -1.3429e-02,  ...,  1.3541e-03,\n",
       "          -1.0659e-02,  1.0495e-02],\n",
       "         [-3.6830e-04,  1.8373e-02,  3.6954e-02,  ..., -6.9785e-03,\n",
       "          -3.6250e-03,  1.0138e-02]]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_codap.state_dict()['module.prompt.e_p_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ebafda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.weight\n",
      "last.bias\n",
      "prompt.e_p_0\n",
      "prompt.e_k_0\n",
      "prompt.e_a_0\n",
      "prompt.e_p_1\n",
      "prompt.e_k_1\n",
      "prompt.e_a_1\n",
      "prompt.e_p_2\n",
      "prompt.e_k_2\n",
      "prompt.e_a_2\n",
      "prompt.e_p_3\n",
      "prompt.e_k_3\n",
      "prompt.e_a_3\n",
      "prompt.e_p_4\n",
      "prompt.e_k_4\n",
      "prompt.e_a_4\n",
      "number of params: 3916900\n",
      "non trainable parameters 89715556\n",
      "percent of train paramters  4.365909519637821\n"
     ]
    }
   ],
   "source": [
    "for n, p in model_codap.named_parameters():\n",
    "    if \"feat\" in n:\n",
    "        p.requires_grad = False\n",
    "    else: \n",
    "        print(n)\n",
    "n_parameters = sum(p.numel() for p in model_codap.parameters() if p.requires_grad)\n",
    "total_parameters = sum(p.numel() for p in model_codap.parameters())\n",
    "print('number of params:', n_parameters)\n",
    "print('non trainable parameters', total_parameters)\n",
    "print(\"percent of train paramters \", n_parameters/ total_parameters * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b54d0eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.weight\n",
      "last.bias\n",
      "prompt.freq_curr_0\n",
      "prompt.freq_past_0\n",
      "prompt.e_p_0\n",
      "prompt.e_k_0\n",
      "number of params: 768100\n",
      "non trainable parameters 86566956\n",
      "percent of train paramters  0.8872900648141075\n"
     ]
    }
   ],
   "source": [
    "for n, p in model_l2p.named_parameters():\n",
    "    if \"feat\" in n:\n",
    "        p.requires_grad = False\n",
    "    else: \n",
    "        print(n)\n",
    "n_parameters = sum(p.numel() for p in model_l2p.parameters() if p.requires_grad)\n",
    "total_parameters = sum(p.numel() for p in model_l2p.parameters())\n",
    "print('number of params:', n_parameters)\n",
    "print('non trainable parameters', total_parameters)\n",
    "print(\"percent of train paramters \", n_parameters/ total_parameters * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe0403b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.weight\n",
      "last.bias\n",
      "prompt.freq_curr_2\n",
      "prompt.freq_past_2\n",
      "prompt.freq_curr_3\n",
      "prompt.freq_past_3\n",
      "prompt.freq_curr_4\n",
      "prompt.freq_past_4\n",
      "prompt.g_p_0\n",
      "prompt.g_p_1\n",
      "prompt.e_p_2\n",
      "prompt.e_k_2\n",
      "prompt.e_p_3\n",
      "prompt.e_k_3\n",
      "prompt.e_p_4\n",
      "prompt.e_k_4\n",
      "number of params: 569956\n",
      "non trainable parameters 86368672\n",
      "percent of train paramters  0.6599105749825585\n"
     ]
    }
   ],
   "source": [
    "for n, p in model_dual.named_parameters():\n",
    "    if \"feat\" in n:\n",
    "        p.requires_grad = False\n",
    "    else: \n",
    "        print(n)\n",
    "n_parameters = sum(p.numel() for p in model_dual.parameters() if p.requires_grad)\n",
    "total_parameters = sum(p.numel() for p in model_dual.parameters())\n",
    "print('number of params:', n_parameters)\n",
    "print('non trainable parameters', total_parameters)\n",
    "print(\"percent of train paramters \", n_parameters/ total_parameters * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47fdcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.weight\n",
      "last.bias\n",
      "number of params: 76900\n",
      "non trainable parameters 85875556\n",
      "percent of train paramters  0.0895481829544137\n"
     ]
    }
   ],
   "source": [
    "for n, p in model_base.named_parameters():\n",
    "    if \"feat\" in n:\n",
    "        p.requires_grad = False\n",
    "    else: \n",
    "        print(n)\n",
    "n_parameters = sum(p.numel() for p in model_base.parameters() if p.requires_grad)\n",
    "total_parameters = sum(p.numel() for p in model_base.parameters())\n",
    "print('number of params:', n_parameters)\n",
    "print('non trainable parameters', total_parameters)\n",
    "print(\"percent of train paramters \", n_parameters/ total_parameters * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9851f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_codap.prompt.e_k_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d4ead4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dual.prompt.e_p_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db8af0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch ones image\n",
    "import torch\n",
    "img1 = torch.randn(32, 3, 224, 224)\n",
    "img2 = torch.randn(32, 3, 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3dca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = torch.load(\"/data/gaurav/Projects/promptFCL/_outputs/ICCV/CIFAR100/10-task/fedMoon1/vit/coda-iid_fedMoon_1/models/repeat-1/task-1/class.pth\")\n",
    "st2 = torch.load(\"/data/gaurav/Projects/promptFCL/_outputs/ICCV/CIFAR100/10-task/fedMoon1/vit/coda-iid_fedMoon_1/models/repeat-1/task-3/class.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18047e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "model1 = copy.deepcopy(model_codap)\n",
    "model2 = copy.deepcopy(model_codap)\n",
    "model1 = torch.nn.DataParallel(model1)\n",
    "model2 = torch.nn.DataParallel(model2)\n",
    "# model1.cuda(), model2.cuda()\n",
    "model1.cuda()\n",
    "model2.cuda()\n",
    "\n",
    "model1.load_state_dict(st1)\n",
    "model2.load_state_dict(st2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992bfd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.forward(img1.cuda(), train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92cfafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nega = cos(logits1, logits2)\n",
    "# nega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bd07b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posi = cos(logits1, logits3)\n",
    "# posi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "774e17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre logits layer\n",
    "# logits1[2]\n",
    "\n",
    "_, _, logits1 = model1(img1.cuda(), train  = True)\n",
    "_, _, logits3 = model2(img1.cuda(), train  = True)\n",
    "_, _, logits2 = model2(img2.cuda(), train  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6452708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a621d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25ff5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "posi = cos(logits1, logits3)\n",
    "nega = cos(logits1, logits2)\n",
    "numerator = torch.exp(posi/tau)\n",
    "denominator = torch.exp(posi/tau) + torch.exp(nega/tau)\n",
    "fedmoonLoss = -torch.log(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fccb6c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3754, 0.5885, 0.4507, 0.5819, 0.5680, 0.5168, 0.5410, 0.5828, 0.5709,\n",
       "        0.6081, 0.5433, 0.5738, 0.5530, 0.5750, 0.4804, 0.5005, 0.5351, 0.5394,\n",
       "        0.5487, 0.1577, 0.5285, 0.3295, 0.5620, 0.5999, 0.5823, 0.4637, 0.5695,\n",
       "        0.5008, 0.4366, 0.3534, 0.5314, 0.6124], device='cuda:0',\n",
       "       grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedmoonLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12f3be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_codap = torch.nn.DataParallel(model_codap)\n",
    "model_codap = model_codap.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ebf8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "m1 = copy.deepcopy(model_codap) #.load_state_dict(st1)\n",
    "m2 = copy.deepcopy(model_codap) #.load_state_dict(st2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "591a4e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.load_state_dict(st1)\n",
    "m2.load_state_dict(st2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66bbee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0., device='cuda:0')\n",
      "1 tensor(0., device='cuda:0')\n",
      "2 tensor(0., device='cuda:0')\n",
      "3 tensor(0., device='cuda:0')\n",
      "4 tensor(0., device='cuda:0')\n",
      "5 tensor(0., device='cuda:0')\n",
      "6 tensor(0., device='cuda:0')\n",
      "7 tensor(0., device='cuda:0')\n",
      "8 tensor(0., device='cuda:0')\n",
      "9 tensor(0., device='cuda:0')\n",
      "10 tensor(-0.7681, device='cuda:0')\n",
      "11 tensor(0.6289, device='cuda:0')\n",
      "12 tensor(1.1336, device='cuda:0')\n",
      "13 tensor(1.1710, device='cuda:0')\n",
      "14 tensor(0.7873, device='cuda:0')\n",
      "15 tensor(-1.1305, device='cuda:0')\n",
      "16 tensor(-1.2147, device='cuda:0')\n",
      "17 tensor(1.3906, device='cuda:0')\n",
      "18 tensor(-0.8674, device='cuda:0')\n",
      "19 tensor(-1.1766, device='cuda:0')\n",
      "20 tensor(1.8422, device='cuda:0')\n",
      "21 tensor(1.5355, device='cuda:0')\n",
      "22 tensor(-1.3895, device='cuda:0')\n",
      "23 tensor(-0.9359, device='cuda:0')\n",
      "24 tensor(-1.2834, device='cuda:0')\n",
      "25 tensor(1.8066, device='cuda:0')\n",
      "26 tensor(2.0858, device='cuda:0')\n",
      "27 tensor(-1.5423, device='cuda:0')\n",
      "28 tensor(-0.6096, device='cuda:0')\n",
      "29 tensor(-1.3317, device='cuda:0')\n",
      "30 tensor(0., device='cuda:0')\n",
      "31 tensor(0., device='cuda:0')\n",
      "32 tensor(0., device='cuda:0')\n",
      "33 tensor(0., device='cuda:0')\n",
      "34 tensor(0., device='cuda:0')\n",
      "35 tensor(0., device='cuda:0')\n",
      "36 tensor(0., device='cuda:0')\n",
      "37 tensor(0., device='cuda:0')\n",
      "38 tensor(0., device='cuda:0')\n",
      "39 tensor(0., device='cuda:0')\n",
      "40 tensor(0., device='cuda:0')\n",
      "41 tensor(0., device='cuda:0')\n",
      "42 tensor(0., device='cuda:0')\n",
      "43 tensor(0., device='cuda:0')\n",
      "44 tensor(0., device='cuda:0')\n",
      "45 tensor(0., device='cuda:0')\n",
      "46 tensor(0., device='cuda:0')\n",
      "47 tensor(0., device='cuda:0')\n",
      "48 tensor(0., device='cuda:0')\n",
      "49 tensor(0., device='cuda:0')\n",
      "50 tensor(0., device='cuda:0')\n",
      "51 tensor(0., device='cuda:0')\n",
      "52 tensor(0., device='cuda:0')\n",
      "53 tensor(0., device='cuda:0')\n",
      "54 tensor(0., device='cuda:0')\n",
      "55 tensor(0., device='cuda:0')\n",
      "56 tensor(0., device='cuda:0')\n",
      "57 tensor(0., device='cuda:0')\n",
      "58 tensor(0., device='cuda:0')\n",
      "59 tensor(0., device='cuda:0')\n",
      "60 tensor(0., device='cuda:0')\n",
      "61 tensor(0., device='cuda:0')\n",
      "62 tensor(0., device='cuda:0')\n",
      "63 tensor(0., device='cuda:0')\n",
      "64 tensor(0., device='cuda:0')\n",
      "65 tensor(0., device='cuda:0')\n",
      "66 tensor(0., device='cuda:0')\n",
      "67 tensor(0., device='cuda:0')\n",
      "68 tensor(0., device='cuda:0')\n",
      "69 tensor(0., device='cuda:0')\n",
      "70 tensor(0., device='cuda:0')\n",
      "71 tensor(0., device='cuda:0')\n",
      "72 tensor(0., device='cuda:0')\n",
      "73 tensor(0., device='cuda:0')\n",
      "74 tensor(0., device='cuda:0')\n",
      "75 tensor(0., device='cuda:0')\n",
      "76 tensor(0., device='cuda:0')\n",
      "77 tensor(0., device='cuda:0')\n",
      "78 tensor(0., device='cuda:0')\n",
      "79 tensor(0., device='cuda:0')\n",
      "80 tensor(0., device='cuda:0')\n",
      "81 tensor(0., device='cuda:0')\n",
      "82 tensor(0., device='cuda:0')\n",
      "83 tensor(0., device='cuda:0')\n",
      "84 tensor(0., device='cuda:0')\n",
      "85 tensor(0., device='cuda:0')\n",
      "86 tensor(0., device='cuda:0')\n",
      "87 tensor(0., device='cuda:0')\n",
      "88 tensor(0., device='cuda:0')\n",
      "89 tensor(0., device='cuda:0')\n",
      "90 tensor(0., device='cuda:0')\n",
      "91 tensor(0., device='cuda:0')\n",
      "92 tensor(0., device='cuda:0')\n",
      "93 tensor(0., device='cuda:0')\n",
      "94 tensor(0., device='cuda:0')\n",
      "95 tensor(0., device='cuda:0')\n",
      "96 tensor(0., device='cuda:0')\n",
      "97 tensor(0., device='cuda:0')\n",
      "98 tensor(0., device='cuda:0')\n",
      "99 tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "     a= model2.state_dict()['module.prompt.e_p_0'][i] - model1.state_dict()['module.prompt.e_p_0'][i]\n",
    "     print( i , torch.sum(a))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c69f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.state_dict()['module.prompt.e_p_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722c572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptFCL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
